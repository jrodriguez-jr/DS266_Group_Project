{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f697fec28a"
      },
      "source": [
        "</p>\n",
        "<p>-adding custom schedule [improved learning]</p>\n",
        "<p>-adding attention weights to output for viz </p>\n",
        "<p>-extracted pre-training word embeddings/post embedding weights to output for viz </p>\n",
        "<p>-updated Transformer, Encoding and Positional Encoding classes to be able to load pre-trained Embeddings</p>\n",
        "<p>-Adding FastText Twitter Embeddings</p>\n",
        "<p>-Training with Different Settings</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFwSaNB8jF7s"
      },
      "source": [
        "<style>\n",
        "td {\n",
        "  text-align: center;\n",
        "}\n",
        "\n",
        "th {\n",
        "  text-align: center;\n",
        "}\n",
        "</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swymtxpl7W7w"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following codes ensures the words embeddings have the same result after being randomly initialized"
      ],
      "metadata": {
        "id": "fUVUPmpZwfcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random number generation\n",
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n"
      ],
      "metadata": {
        "id": "uj-XUHm-wWdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acgF9rXfaiRP",
        "outputId": "b3cd8b14-deab-42b0-fdba-d743602d4b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the Directory Containing the CSV File\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/DS266 Project')"
      ],
      "metadata": {
        "id": "FNO7MPwxarDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfV1batAwq9j"
      },
      "source": [
        "Begin by installing [TensorFlow Datasets](https://tensorflow.org/datasets) for loading the dataset and [TensorFlow Text](https://www.tensorflow.org/text) for text preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFG0NDRu5mYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2176300c-de0a-4918-c6a6-02b1f429cbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "Package libcudnn8 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "\u001b[1;31mE: \u001b[0mVersion '8.1.0.77-1+cuda11.2' for 'libcudnn8' was not found\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -q\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text -q\n",
        "!pip install -q protobuf~=3.20.3\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible TensorFlow version\n",
        "!pip uninstall tensorflow -y -q\n",
        "!pip install tensorflow==2.15 -q\n",
        "\n",
        "# Reinstall tf-keras to resolve any potential dependency conflicts\n",
        "!pip uninstall tf-keras -y -q\n",
        "!pip install tf-keras -q"
      ],
      "metadata": {
        "id": "sfB0JATpjTEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3d3c4d-08f1-4896-8284-49a71c9b1c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15 -q #it needs it again for some reason"
      ],
      "metadata": {
        "id": "Q-VgaWpbm21T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb43e12-d87f-4a57-c46e-3a419b160f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.15.0 which is incompatible.\n",
            "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow-text -y -q\n",
        "!pip install tensorflow-text==2.15 -q"
      ],
      "metadata": {
        "id": "KHCOdSJLuYLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYpLBSjxJmG"
      },
      "source": [
        "Import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjJJyJTZYebt"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as text\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf_WUi2HLhzf"
      },
      "source": [
        "## Data handling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCvXbPkccV1"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTEVgBxklzdq"
      },
      "source": [
        "read the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV File\n",
        "import pandas as pd\n",
        "load_data = 'train_enhanced_cleaned.csv'\n",
        "tweets_df = pd.read_csv(load_data).drop_duplicates()\n",
        "tweets_df.head(3)"
      ],
      "metadata": {
        "id": "lw7axoYfayav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6eca4d48-4e3d-45a3-c23a-dd5dc9eb251e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  location   our deeds are the reason of this ea...       1\n",
              "1  location   forest fire near la ronge sask  can...       1\n",
              "2  location   all residents asked to shelter in p...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ceb1817-3450-4847-837b-081fc9d91c95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>location   our deeds are the reason of this ea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>location   forest fire near la ronge sask  can...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>location   all residents asked to shelter in p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ceb1817-3450-4847-837b-081fc9d91c95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ceb1817-3450-4847-837b-081fc9d91c95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ceb1817-3450-4847-837b-081fc9d91c95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a9d300b-10c3-4266-a247-feaa7db0e970\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a9d300b-10c3-4266-a247-feaa7db0e970')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a9d300b-10c3-4266-a247-feaa7db0e970 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tweets_df",
              "summary": "{\n  \"name\": \"tweets_df\",\n  \"rows\": 7066,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7002,\n        \"samples\": [\n          \"location oil spill refugio oil spill may have been costlier bigger than projected weblink   negative  news   social concern non irony fear \",\n          \"location bloody bloody hell what a day  i havent even really done anything  just  tired  of everything  thought vaca would help but it only did so much     negative  news   social concern non irony sadness\",\n          \"location exploded oh yeah my ipod almost exploded last night i was using it while charging and shit was sparking akxbskdn almost died negative  news   social concern non irony disgust \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJxTd6aVnZyh"
      },
      "source": [
        "### Set up the tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mopr6oKUlzds"
      },
      "source": [
        "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n",
        "\n",
        "Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = tweets_df['text']\n",
        "labels = tweets_df['target']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WiZB9l9ubV0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make them the same"
      ],
      "metadata": {
        "id": "r880v9idOy2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "overall sentences"
      ],
      "metadata": {
        "id": "tCflagRrPYYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Instantiate the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on your text data\n",
        "tokenizer.fit_on_texts(sentences)\n"
      ],
      "metadata": {
        "id": "FlLcttf77sHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Set MAX TOKENS"
      ],
      "metadata": {
        "id": "bdgOE9kswYai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS =30\n",
        "# Convert sentences to sequences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Pad sequences\n",
        "sequences = pad_sequences(sequences, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "# Convert labels to NumPy array\n",
        "\"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "g2IH6BJs7hGZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "17f0d670-4d24-422e-8d98-c6057f0a9338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yb35sTJcZq9"
      },
      "source": [
        "### Set up a data pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHsns5obJhN"
      },
      "source": [
        "The following function takes batches of text as input, and converts them to a format suitable for training.\n",
        "\n",
        "1. It tokenizes them into ragged batches.\n",
        "2. It trims each to be no longer than `MAX_TOKENS`.\n",
        "3. It splits the target (English) tokens into inputs and labels. These are shifted by one step so that at each input location the `label` is the id of the next token.\n",
        "4. It converts the `RaggedTensor`s to padded dense `Tensor`s.\n",
        "5. It returns an `(inputs, labels)` pair.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Set Batch Size"
      ],
      "metadata": {
        "id": "wA_j8tjcykSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Shuffle and batch the dataset\n",
        "BUFFER_SIZE = len(sequences)\n",
        "BATCH_SIZE = 64  # You can adjust the batch size as needed\n",
        "\n",
        "# Split the data\n",
        "sequences_train, sequences_val, labels_train, labels_val = train_test_split(sequences, labels, test_size=0.1)\n",
        "\n",
        "# Convert to TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((sequences_train, labels_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((sequences_val, labels_val))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "train_dataset = train_dataset.shuffle(len(sequences_train)).batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_6wwjDir8hcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itSWqk-ivrRg"
      },
      "source": [
        "### Test the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For train_batches\n",
        "for x, y in train_dataset.take(1):  # We only take one batch\n",
        "    print(\"Shape of X:\", x.shape)\n",
        "    print(\"Data type of X:\", x.dtype)  # This will print the data type\n",
        "    print(\"Content of X:\", x.numpy())  # .numpy() converts the tensor to a numpy array\n",
        "    print(\"Shape of Y:\", y.shape)\n",
        "    print(\"Content of Y:\", y.numpy())\n",
        "\n",
        "# For val_batches\n",
        "for x, y in val_dataset.take(1):  # We only take one batch\n",
        "    print(\"Shape of X:\", x.shape)\n",
        "    print(\"Data type of X:\", x.dtype)  # This will print the data type\n",
        "    print(\"Content of X:\", x.numpy())  # .numpy() converts the tensor to a numpy array\n",
        "    print(\"Shape of Y:\", y.shape)\n",
        "    print(\"Content of Y:\", y.numpy())"
      ],
      "metadata": {
        "id": "kE1DTUdA8k0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54e8d37-3db8-4477-abf0-1178a991e8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (64, 30)\n",
            "Data type of X: <dtype: 'int32'>\n",
            "Content of X: [[    4   261   705 ...     6     5    25]\n",
            " [   83 14149    24 ...     6     5    22]\n",
            " [    4   294   767 ...     0     0     0]\n",
            " ...\n",
            " [    4   180    28 ...     0     0     0]\n",
            " [    4    49   163 ...     0     0     0]\n",
            " [    4   140     9 ...     0     0     0]]\n",
            "Shape of Y: (64,)\n",
            "Content of Y: [0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0]\n",
            "Shape of X: (64, 30)\n",
            "Data type of X: <dtype: 'int32'>\n",
            "Content of X: [[    4   172    20 ...     0     0     0]\n",
            " [    4   426    85 ...     0     0     0]\n",
            " [    4   205 14477 ...     0     0     0]\n",
            " ...\n",
            " [    4   165     9 ...     0     0     0]\n",
            " [    4   151  1206 ...     6     5   907]\n",
            " [    4   275  1591 ...     0     0     0]]\n",
            "Shape of Y: (64,)\n",
            "Content of Y: [0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet, labels in train_dataset.take(1):\n",
        "  break\n",
        "\n",
        "print(tweet.shape)\n",
        "print(labels.shape)\n"
      ],
      "metadata": {
        "id": "iZZS6HuY-n31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00222a32-a5af-4277-e858-92fb571ea990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 30)\n",
            "(64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Location of Saved Training"
      ],
      "metadata": {
        "id": "OhelWo91DZB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the models, and files, if directory does not exist, it creates it."
      ],
      "metadata": {
        "id": "Y7wkIlFm3Eme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_dir = './Final_Work/b64_wm3000_enh_cl_data_base_tx_model_fast_emb_10ep_drophigh/'\n",
        "directory = checkpoint_dir\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n"
      ],
      "metadata": {
        "id": "Llt2ct5-21EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX_h3tCnwgR4"
      },
      "source": [
        " </section>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Define the components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS75Y-9-lkzn"
      },
      "source": [
        "### The positional encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra1IcbzFhnmF"
      },
      "source": [
        "The position encoding function is a stack of sines and cosines that vibrate at different frequencies depending on their location along the depth of the embedding vector. They vibrate across the position axis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Positional Embedding"
      ],
      "metadata": {
        "id": "eJ9x7fldgx08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Update the PositionalEmbedding class to accept pretrained embeddings\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model, pretrained_embeddings=None):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "        if pretrained_embeddings is not None:\n",
        "            self.embedding.build((None,))  # Build the layer to set the weights\n",
        "            self.embedding.set_weights([pretrained_embeddings])  # Set the pretrained weights\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x"
      ],
      "metadata": {
        "id": "o8ZQ4dm2SH26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6chjIrOVSYp"
      },
      "source": [
        "To implement these attention layers, start with a simple base class that just contains the component layers. Each use-case will be implemented as a subclass. It's a little more code to write this way, but it keeps the intention clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VLa5QcdPpv5"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        return_attention_scores=True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "_wXyZ6NvMZ6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yb-IV0Nlzd0"
      },
      "source": [
        "The network consists of two linear layers (`tf.keras.layers.Dense`) with a ReLU activation in-between, and a dropout layer. As with the attention layers the code here also includes the residual connection and normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAYLeu0uwXYK"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQBlOVQU_hUt"
      },
      "source": [
        "Test the layer, the output is the same shape as the input:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### The encoder layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kRUT__Ly9HH"
      },
      "source": [
        "Here is the definition of the `EncoderLayer`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    #print(f\"Shape of inputs to encoder layer: {x.shape}\")  # Add this line\n",
        "    x = self.self_attention(x)\n",
        "    #print(f\"Shape after self_attention: {x.shape}\")  # Add this line\n",
        "\n",
        "    x = self.ffn(x)\n",
        "    return x\n",
        "\n",
        "  @property\n",
        "  def last_attn_scores(self):\n",
        "    return self.self_attention.last_attn_scores"
      ],
      "metadata": {
        "id": "cWM2baZ6Myxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeXHMUlb6q6F"
      },
      "source": [
        "And a quick test, the output will have the same shape as the input:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### The encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA6sVo5rlzd3"
      },
      "source": [
        "The encoder consists of:\n",
        "\n",
        "- A `PositionalEmbedding` layer at the input.\n",
        "- A stack of `EncoderLayer` layers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1, pretrained_embeddings=None):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model, pretrained_embeddings=pretrained_embeddings)\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model=d_model,\n",
        "                         num_heads=num_heads,\n",
        "                         dff=dff,\n",
        "                         dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "      # `x` is token-IDs shape: (batch, seq_len)\n",
        "      #print(f\"Shape of inputs to encoder: {x.shape}\")  # Add this line\n",
        "      x = self.pos_embedding(x)\n",
        "      #print(f\"Shape after pos_embedding: {x.shape}\")  # Add this line\n",
        "\n",
        "\n",
        "      # Add dropout.\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      for i in range(self.num_layers):\n",
        "        x = self.enc_layers[i](x)\n",
        "\n",
        "      #print(\"length: \", x.dtype)\n",
        "      return x  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "\n",
        "    @property\n",
        "    def last_attn_scores(self):\n",
        "      return self.enc_layers[-1].last_attn_scores"
      ],
      "metadata": {
        "id": "OIP4t7iYkNTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3uvMP5vNuOV"
      },
      "source": [
        "Having created the Transformer encoder, it's time to build the Transformer model and train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## The Transformer Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is based on last hidden state"
      ],
      "metadata": {
        "id": "6M0aKVuxRRtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(tf.keras.Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "                 input_vocab_size, dropout_rate=0.1, pretrained_embeddings=None):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                               num_heads=num_heads, dff=dff,\n",
        "                               vocab_size=input_vocab_size,\n",
        "                               dropout_rate=dropout_rate,\n",
        "                               pretrained_embeddings=pretrained_embeddings)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context = inputs\n",
        "        context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "        logits = self.final_layer(context[:, -1, :])  # Use the last hidden state\n",
        "        return logits"
      ],
      "metadata": {
        "id": "GyyESE_xhsqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g08YOE-zHRqY"
      },
      "source": [
        "# Try it out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Location of Saved Model and Results"
      ],
      "metadata": {
        "id": "TdH9cAACIvr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: run again if you wish to change the directory where its saved"
      ],
      "metadata": {
        "id": "dbzoD922PRIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './Final_Work/ep20_wm6000_b64_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/'\n",
        "checkpoint_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IH5r2hlsgheE",
        "outputId": "6ff3cc23-702b-4732-a7d1-7cd36f7ac402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./Final_Work/ep20_wm6000_b64_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n"
      ],
      "metadata": {
        "id": "GpRgsRFtI1Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjwMq_ixlzd5"
      },
      "source": [
        "\n",
        "\n",
        "The base model described in the original Transformer paper used `num_layers=6`, `d_model=512`, and `dff=2048`.\n",
        "\n",
        "The number of self-attention heads remains the same (`num_heads=8`).\n",
        "\n",
        "We save the hyperparameters on the drive with the same trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the path where you want to save the CSV\n",
        "save_path = './'+checkpoint_dir+'/hyperparameters.csv'\n",
        "\n",
        "\n",
        "hyperparameters = {\n",
        "    'num_layers': 2,\n",
        "    'd_model': 100,\n",
        "    'dff': 256,\n",
        "    'num_heads': 2,\n",
        "    'dropout_rate': 0.6\n",
        "}\n",
        "\n",
        "# Convert the hyperparameters dictionary to a DataFrame\n",
        "hyperparameters_df = pd.DataFrame([hyperparameters])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "hyperparameters_df.to_csv(save_path, index=False)\n"
      ],
      "metadata": {
        "id": "GQ-uIJ8v5-8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the hyperparameters from the CSV file\n",
        "loaded_hyperparameters_df = pd.read_csv(save_path)\n",
        "\n",
        "# Access the hyperparameters\n",
        "loaded_hyperparameters = loaded_hyperparameters_df.iloc[0].to_dict()\n",
        "\n",
        "#HYPERPARAMETERS\n",
        "num_layers = int(loaded_hyperparameters['num_layers'])\n",
        "d_model = int(loaded_hyperparameters['d_model'])\n",
        "num_heads = int(loaded_hyperparameters['num_heads'])\n",
        "dff = int(loaded_hyperparameters['dff'])\n",
        "dropout_rate = float(loaded_hyperparameters['dropout_rate'])\n"
      ],
      "metadata": {
        "id": "rLpjFbHOlNa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the Pre-Trained Embeddings"
      ],
      "metadata": {
        "id": "9AY2Sa4VLNwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings from the CSV file\n",
        "path_to_embeddings = 'fast_text_twitter_embeddings.csv'\n",
        "loaded_embeddings_df = pd.read_csv(path_to_embeddings)\n",
        "loaded_embeddings = loaded_embeddings_df.values\n",
        "\n",
        "# Create a new PositionalEmbedding layer for the new model\n",
        "new_pos_embedding_layer = PositionalEmbedding(\n",
        "    vocab_size=len(tokenizer.word_index) + 1,\n",
        "    d_model=d_model,\n",
        "    pretrained_embeddings=loaded_embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "2bZAMu8OLNQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCIYp6ASObVs",
        "outputId": "87559a94-8810-4e24-e4c2-7ede072bdd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17984, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYbXDEhhlzd6"
      },
      "source": [
        "###Instantiate the `Transformer` model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transformer = TransformerClassifier(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=len(tokenizer.word_index) + 1,\n",
        "    dropout_rate=dropout_rate,\n",
        "    pretrained_embeddings=loaded_embeddings #new\n",
        ")\n"
      ],
      "metadata": {
        "id": "8XdL0RB168F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extract initial weights"
      ],
      "metadata": {
        "id": "80ZOIDWnEW6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the transformer to extract initial word weights (for later analysis)"
      ],
      "metadata": {
        "id": "isz93EeuwGAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build the transformer to initialize weights\n",
        "transformer.build(input_shape=(None, MAX_TOKENS))\n",
        "\n",
        "# Access the weights of the embedding layer within the PositionalEmbedding layer\n",
        "initial_embeddings = transformer.encoder.pos_embedding.embedding.get_weights()[0]\n"
      ],
      "metadata": {
        "id": "s23I333Wv_5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The words size list is dependent on the data wrangling done before it. If the data warngling and tokenization doesnt change then the embeddings will not change, and we can start loading hte embeddings instead of randomly creating them on start."
      ],
      "metadata": {
        "id": "9CTqUdMLo-Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial embeddings should be just the loaded embeddings, below am doing a sanity check"
      ],
      "metadata": {
        "id": "x228xd-ZO2IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_embeddings.shape, initial_embeddings[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mveleg9Twxga",
        "outputId": "b206405a-0776-4ef2-b7a1-fd955187db4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17984, 100),\n",
              " array([-3.4806e-01,  4.6123e-01, -2.1694e-01,  6.1845e-02,  2.3122e-02,\n",
              "        -4.4194e-01, -2.8939e-01, -1.4042e-01,  2.0356e-01, -1.4766e-03,\n",
              "         1.4099e-01,  1.6973e-01, -2.5894e-01,  1.1918e-01, -5.6644e-02,\n",
              "        -1.9194e-01, -4.6347e-01, -2.3882e-01, -4.2290e-01,  1.1425e-01,\n",
              "        -2.7304e-02,  2.0090e-01, -8.0673e-02,  1.7944e-01, -4.0131e-01,\n",
              "         4.2389e-01,  8.1304e-02,  3.9369e-01, -6.6077e-02, -3.1873e-01,\n",
              "         2.7647e-01,  4.5163e-01, -3.2050e-01, -8.9602e-05,  8.9974e-01,\n",
              "        -4.2211e-01, -4.1124e-01, -1.8637e-02,  6.1292e-01, -3.5513e-01,\n",
              "         2.9589e-01,  3.1024e-01,  5.1241e-01,  4.6033e-01, -3.3272e-01,\n",
              "         1.2669e-01, -6.3074e-02, -5.8398e-02, -4.7630e-01,  3.9685e-01,\n",
              "        -4.0602e-01, -6.9270e-01, -6.0114e-01,  3.2997e-01, -2.6665e-01,\n",
              "        -7.2613e-01, -6.1922e-01, -4.7685e-01, -2.4736e-01,  1.6644e-01,\n",
              "        -1.8508e-01,  2.0447e-01,  2.3464e-01, -8.0302e-02,  1.1650e+00,\n",
              "        -1.2155e-02, -2.4816e-01, -2.7170e-02, -3.3387e-01,  3.4174e-01,\n",
              "        -6.8687e-01,  7.0614e-01,  1.6891e-01,  1.3400e-02,  3.5246e-01,\n",
              "        -3.7677e-02,  4.1160e-01, -1.8286e-01,  4.2182e-01,  1.6571e-01,\n",
              "         1.2066e-01, -1.7407e-01, -1.7991e-01,  1.4452e-02,  2.1754e-01,\n",
              "         9.9649e-01, -1.0134e-03, -2.3007e-02, -1.8162e-01, -3.1818e-01,\n",
              "        -3.6765e-01, -6.0209e-01,  3.0666e-01, -2.0385e-01, -3.6655e-02,\n",
              "         5.7922e-01,  4.5266e-01,  7.1265e-02, -3.5784e-02, -3.4018e-01],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_embeddings.shape, loaded_embeddings[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4p4T8EPOsQ2",
        "outputId": "20240600-da22-4df2-eab2-ab38094ae5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17984, 100),\n",
              " array([-3.48060012e-01,  4.61230010e-01, -2.16940001e-01,  6.18450008e-02,\n",
              "         2.31219996e-02, -4.41940010e-01, -2.89389998e-01, -1.40420005e-01,\n",
              "         2.03559995e-01, -1.47659995e-03,  1.40990004e-01,  1.69729993e-01,\n",
              "        -2.58940011e-01,  1.19180001e-01, -5.66440001e-02, -1.91939995e-01,\n",
              "        -4.63470012e-01, -2.38820001e-01, -4.22899991e-01,  1.14249997e-01,\n",
              "        -2.73039993e-02,  2.00900003e-01, -8.06730017e-02,  1.79440007e-01,\n",
              "        -4.01309997e-01,  4.23889995e-01,  8.13039988e-02,  3.93689990e-01,\n",
              "        -6.60770014e-02, -3.18729997e-01,  2.76470006e-01,  4.51629996e-01,\n",
              "        -3.20499986e-01, -8.96019992e-05,  8.99739981e-01, -4.22109991e-01,\n",
              "        -4.11240011e-01, -1.86369997e-02,  6.12919986e-01, -3.55129987e-01,\n",
              "         2.95890003e-01,  3.10240000e-01,  5.12409985e-01,  4.60330009e-01,\n",
              "        -3.32720011e-01,  1.26690000e-01, -6.30740002e-02, -5.83980009e-02,\n",
              "        -4.76300001e-01,  3.96849990e-01, -4.06019986e-01, -6.92700028e-01,\n",
              "        -6.01140022e-01,  3.29970002e-01, -2.66649991e-01, -7.26130009e-01,\n",
              "        -6.19220018e-01, -4.76850003e-01, -2.47360006e-01,  1.66439995e-01,\n",
              "        -1.85080007e-01,  2.04469994e-01,  2.34640002e-01, -8.03020000e-02,\n",
              "         1.16499996e+00, -1.21550001e-02, -2.48160005e-01, -2.71700006e-02,\n",
              "        -3.33869994e-01,  3.41740012e-01, -6.86869979e-01,  7.06139982e-01,\n",
              "         1.68909997e-01,  1.33999996e-02,  3.52459997e-01, -3.76770012e-02,\n",
              "         4.11599994e-01, -1.82860002e-01,  4.21820015e-01,  1.65710002e-01,\n",
              "         1.20660000e-01, -1.74070001e-01, -1.79910004e-01,  1.44520001e-02,\n",
              "         2.17539996e-01,  9.96490002e-01, -1.01340003e-03, -2.30069999e-02,\n",
              "        -1.81620002e-01, -3.18179995e-01, -3.67650002e-01, -6.02090001e-01,\n",
              "         3.06659997e-01, -2.03850001e-01, -3.66550013e-02,  5.79219997e-01,\n",
              "         4.52659994e-01,  7.12649971e-02, -3.57839987e-02, -3.40180010e-01]))"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Name the Model"
      ],
      "metadata": {
        "id": "GWwFDeBJD5t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model created with cleaned enhanced data set and initialize with randome ebeddings and 2 attention heads\n",
        "model_base_name = 'wm6000ep20_b64_cl_enh_more_dat_bl_tx_w_tw_2h_2l_d06_dff256'"
      ],
      "metadata": {
        "id": "0Hj_-5UFqu4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create Readme File"
      ],
      "metadata": {
        "id": "lU93v8HTqv_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming 'initial_embeddings' contains the weights from the embedding layer\n",
        "#even if they were loaded\n",
        "initial_embeddings_df = pd.DataFrame(initial_embeddings)\n",
        "save_to = checkpoint_dir + 'initial_embeddings.csv'\n",
        "initial_embeddings_df.to_csv(save_to, index=False)\n",
        "# Define the directory and file name\n",
        "directory = checkpoint_dir\n",
        "file_name = 'initial_embeddings.csv'\n",
        "how_were_embeddings_created ='loaded from FastText Twitter pre-trained embeddings'\n",
        "note = \"wu to 6000, doing 20 epcohs , making batch size to 64,trying with two  head two layers and drop rate 0.6 with 90% 10% split in train/val and dff = 256\"\n",
        "\n",
        "readme_content = f\"\"\"README\n",
        "\n",
        "\n",
        "Note: {note}\n",
        "These embeddings were {how_were_embeddings_created}.\n",
        "These  embeddings are associated with the model checkpoints saved during training pertaining to the model with\n",
        "base name '{model_base_name}', these word embeddings\n",
        "can be used for a pre- and post- training analysis of the training effects to each word embedding.\n",
        "The initial state of the  word embeddings before training are saved in the '{directory}' directory.\n",
        "The file '{file_name}' contains the embeddings in CSV format.\n",
        "\n",
        "The hyperparameters for this model ara saved on this directory in hyperparameters.csv file\n",
        "The results of this training run will be saved under CSV_Results-{model_base_name }'.csv file.\n",
        "The learning schedule plot, training loss plot and training model summary will also saved in this directory.\n",
        "\"\"\"\n",
        "# path\n",
        "readme_file_path = f'{directory}/readme.txt'\n",
        "\n",
        "# Write the readme content to the file\n",
        "with open(readme_file_path, 'w') as readme_file:\n",
        "    readme_file.write(readme_content)\n",
        "\n",
        "# Print a success message\n",
        "print(f\"The readme.txt file has been successfully written to the '{directory}' directory.\")\n",
        "\n",
        "print(readme_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK3FYzFg3MtQ",
        "outputId": "6f1d9115-5dbc-409c-ef42-5a2471f27c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The readme.txt file has been successfully written to the './Final_Work/ep20_wm6000_b64_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/' directory.\n",
            "README\n",
            "\n",
            "\n",
            "Note: wu to 6000, doing 20 epcohs , making batch size to 64,trying with two  head two layers and drop rate 0.6 with 90% 10% split in train/val and dff = 256\n",
            "These embeddings were loaded from FastText Twitter pre-trained embeddings.\n",
            "These  embeddings are associated with the model checkpoints saved during training pertaining to the model with\n",
            "base name 'wm6000ep20_b64_cl_enh_more_dat_bl_tx_w_tw_2h_2l_d06_dff256', these word embeddings\n",
            "can be used for a pre- and post- training analysis of the training effects to each word embedding.\n",
            "The initial state of the  word embeddings before training are saved in the './Final_Work/ep20_wm6000_b64_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/' directory.\n",
            "The file 'initial_embeddings.csv' contains the embeddings in CSV format.\n",
            "\n",
            "The hyperparameters for this model ara saved on this directory in hyperparameters.csv file\n",
            "The results of this training run will be saved under CSV_Results-wm6000ep20_b64_cl_enh_more_dat_bl_tx_w_tw_2h_2l_d06_dff256'.csv file.\n",
            "The learning schedule plot, training loss plot and training model summary will also saved in this directory.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Plotting Tool and Saving History"
      ],
      "metadata": {
        "id": "1n-x8IiMq4CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, checkpoint_dir):\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.xticks(range(0, len(history['loss'] + 1)))\n",
        "  plt.plot(history['loss'], label=\"training\", marker='o')\n",
        "  plt.plot(history['val_loss'], label=\"validation\", marker='o')\n",
        "  plt.legend()\n",
        "  plt.savefig(checkpoint_dir+'loss_history_plot.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "I6bFnSYqB1Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def history_to_csv(history, num_layers, d_model, num_heads, dff, dropout_rate, model_base_name, load_data, checkpoint_dir, path_to_embeddings):\n",
        "    # Assuming 'history' is your DataFrame\n",
        "    history_copy = history.copy(deep=True)\n",
        "\n",
        "    # Add 'Epoch' column\n",
        "    history_copy['Epoch'] = range(1, len(history_copy) + 1)\n",
        "     # Add 'name' and 'data' columns\n",
        "    history_copy['name'] = model_base_name\n",
        "\n",
        "    history_copy['data'] = load_data\n",
        "    history_copy['word_embeddings'] = path_to_embeddings\n",
        "    # Add hyperparameters\n",
        "    history_copy['num_layers'] = num_layers\n",
        "    history_copy['d_model'] = d_model\n",
        "    history_copy['num_heads'] = num_heads\n",
        "    history_copy['dff'] = dff\n",
        "    history_copy['dropout_rate'] = dropout_rate\n",
        "\n",
        "\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_file_name = \"CSV_Results-\" + model_base_name + \".csv\"\n",
        "    csv_file_path = os.path.join(checkpoint_dir, csv_file_name)\n",
        "    history_copy.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "WokzCNqzzGuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jTvJsXquaHW"
      },
      "source": [
        "####Save and Print the summary of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsUPhlfEtOjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad77e65-2a05-4381-c571-1444f06efd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_classifier_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_3 (Encoder)         multiple                  2063712   \n",
            "                                                                 \n",
            " dense_9 (Dense)             multiple                  101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2063813 (7.87 MB)\n",
            "Trainable params: 2063813 (7.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#print(transformer.summary())\n",
        "\n",
        "with open(checkpoint_dir+'model_summary.txt', 'w') as f:\n",
        "    transformer.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "print(transformer.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(transformer, to_file=\"model_diagram.png\", show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "U4Y2whmn9Y2z",
        "outputId": "b858fc0a-53af-4ddc-8757-9de3367a43e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfoBfC2oQtEy"
      },
      "source": [
        "# Training\n",
        "\n",
        "It's time to prepare the model and start training it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "### Set up the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4G5bS6lzd5"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQdOO1axwEI"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=6000): #chnagefrom 4000\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "### Set up the loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n"
      ],
      "metadata": {
        "id": "cnvxm8MpE2u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTb2S4RnQ8DU"
      },
      "source": [
        "Test the custom learning rate scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xij3MwYVRAAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "7bc8d784-e75d-4770-9818-dcc760ac4216"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnNklEQVR4nO3deVxU9foH8M8MMMM6MyIyrAIqigsuoSLmUkliWmmby/WX5vVmt6tt2mY3tcUuZnbrWpbZZrtLe6Ym4VImoiIIKLiiCDogIDOAss18f38gJycRAYHDDJ/36zUv4JznzDxfRp3H73nO9yiEEAJERERE1ChKuRMgIiIiskUsooiIiIiagEUUERERUROwiCIiIiJqAhZRRERERE3AIoqIiIioCVhEERERETWBo9wJ2DOLxYIzZ87Aw8MDCoVC7nSIiIioAYQQKCkpgZ+fH5TKq883sYhqQWfOnEFgYKDcaRAREVETnD59GgEBAVfdzyKqBXl4eACoeRM0Go3M2RAREVFDmEwmBAYGSp/jV8MiqgXVnsLTaDQsooiIiGzMtVpx2FhORERE1AQsooiIiIiagEUUERERUROwiCIiIiJqAhZRRERERE3AIoqIiIioCVhEERERETUBiygiIiKiJmARRURERNQELKKIiIiImoBFFBEREVETsIgiIiIiagIWUWTzqswWWCxC7jSIiKidYRFFNu1oXgl6L/oFL/50UO5UiIionWERRTZt7d7TqKy24JOEU8g3lcudDhERtSMsosim5RZflL7/ck+2jJkQEVF7wyKKbFparlH6/svEbFSZLTJmQ0RE7QmLKLJZ58sqkXO+ZiZK7ahEfkkFthzMkzkrIiJqL1hEkc2qnYUK8XLDQyO6AAA+STgpY0ZERNSesIgim1VbRPXx1+JvkUFwUCqwJ6sImQaTzJkREVF7wCKKbFZaTk0R1ddfCx+tM0b30gMAPks4JWdaRETUTrCIIpt1+UwUANwfFQQA+C45F6byKtnyIiKi9oFFFNmkwtIKaXmDPv4aAEBUl44I9XbHhUoz1u45LWd6RETUDrCIIptUOwvVxcsNHs5OAACFQoGZw0IAAB//kcXlDoiIqEWxiCKbVNsPFR6gtdo+YYA/vNxVOGMsx8a0s3KkRkRE7QSLKLJJtTNR4f7WRZSzkwPuHxIMAPjg9ywIwRsTExFRy2ARRTbpakUUAPzfkM5QOyqRlmtEYlZRa6dGRETtBIsosjnnSipw1lgOhQLoXUcR1dFdjXsiAgAAH/x+orXTIyKidoJFFNmc9Muayt3VjnXG1DaY/5qRj+PnSlstNyIiaj9YRJHNqe9UXq2undwR3bNm8U3ORhERUUtgEUU2J1W6Mk9Xb9xDI2vup/dNUi7OGi+2dFpERNTOsIgim5PegJkoABgU7InBIZ6oNFuw6jfORhERUfNiEUU2Jb+kHAbTpaZyP8014x+5pRsA4Ks92SgorWjp9IiIqB1hEUU2pXYWqlsnd7hdpan8csO6eaFfgBblVRZ8uDOrpdMjIqJ2RPYiasWKFQgODoazszMiIyOxZ8+eeuPXr1+PsLAwODs7Izw8HBs3brTaL4TAwoUL4evrCxcXF0RHR+Po0aNWMa+88gqGDh0KV1dX6HS6K17jwIEDmDJlCgIDA+Hi4oKePXvif//733WPla6f1A91jVN5tRQKBebcEgoA+CzhFIwXeGNiIiJqHrIWUWvXrsXcuXOxaNEi7N+/H/369UNMTAzy8/PrjN+1axemTJmCmTNnIjk5GRMmTMCECROQnp4uxSxduhTLly/HypUrkZiYCDc3N8TExKC8vFyKqaysxH333YeHH364ztdJSkqCt7c3Pv/8cxw8eBD//ve/MX/+fLz99tvN+wugRpP6oQIaVkQBwKgwb4T5eKC0ohqrd51socyIiKi9UQgZ74sRGRmJQYMGScWJxWJBYGAgHnnkETz77LNXxE+aNAllZWXYsGGDtG3IkCHo378/Vq5cCSEE/Pz8MG/ePDz55JMAAKPRCL1ej9WrV2Py5MlWz7d69Wo8/vjjKC4uvmaus2fPRkZGBrZu3drg8ZlMJmi1WhiNRmg01+7foWsb/MqvyC+pwNf/jMLAYM8GH/fTgTN45Ktk6FydsPOZW666vhQREVFDP79lm4mqrKxEUlISoqOj/0xGqUR0dDQSEhLqPCYhIcEqHgBiYmKk+KysLBgMBqsYrVaLyMjIqz5nQxmNRnh61v+hXVFRAZPJZPWg5pNnKkd+SQWUCqBXA5rKLzc23BddvNxQfKEKq/9gbxQREV0/2YqogoICmM1m6PV6q+16vR4Gg6HOYwwGQ73xtV8b85wNsWvXLqxduxazZs2qNy42NhZarVZ6BAYGNvk16Uppl/qhunm7w1XVuJkkB6UCj0XX9Ea999sJ9kYREdF1k72xvK1LT0/H+PHjsWjRIowePbre2Pnz58NoNEqP06dPt1KW7UOqtD6UrknH39HXDz30Higpr8b7XMWciIiuk2xFlJeXFxwcHJCXl2e1PS8vDz4+PnUe4+PjU2987dfGPGd9Dh06hFGjRmHWrFl4/vnnrxmvVquh0WisHtR8/lxks2m/V6VSgbmjuwMAPvojC4VcN4qIiK6DbEWUSqVCREQE4uPjpW0WiwXx8fGIioqq85ioqCireACIi4uT4kNCQuDj42MVYzKZkJiYeNXnvJqDBw/i5ptvxvTp0/HKK6806lhqfkKIBt/upT6je+kR7q/FhUozVu443kzZERFReyTr6by5c+fi/fffxyeffIKMjAw8/PDDKCsrw4wZMwAA06ZNw/z586X4xx57DJs3b8brr7+OzMxMvPDCC9i3bx/mzJkDoGZNoMcffxyLFy/Gjz/+iLS0NEybNg1+fn6YMGGC9DzZ2dlISUlBdnY2zGYzUlJSkJKSgtLSUgA1p/BuvvlmjB49GnPnzoXBYIDBYMC5c+da75dDVvJMFSgovdRU7tv0GT6FQoF5l2ajPk04hTxT+TWOICIiqpus13lPmjQJ586dw8KFC2EwGNC/f39s3rxZagzPzs6GUvlnnTd06FB8+eWXeP755/Hcc88hNDQU33//Pfr06SPFPP300ygrK8OsWbNQXFyMYcOGYfPmzXB2dpZiFi5ciE8++UT6ecCAAQCAbdu24aabbsLXX3+Nc+fO4fPPP8fnn38uxQUFBeHkyZMt9eugeqTmFAMAuus94KJyuK7nGtm9EwYFd8Dek+fx1tajWDwhvBkyJCKi9kbWdaLsHdeJaj7/3XIYy7cew70RAVh2X7/rfr7dJwoxedVuOCoV2PLECHTp5N4MWRIRkT1o8+tEETVG7ZV5fRuxUnl9hnTpiFvCvFFtEVi6+XCzPCcREbUvLKKozRNCSFfm9WngPfMaYv5tYVAqgM0HDdh7sqjZnpeIiNoHFlHU5p01lqOgtBIOSsV1NZX/VajeA5MGdQYALP45AzyzTUREjcEiitq8tEuzUN31HnB2ur6m8r964tZQuKoccOB0MTaknm3W5yYiIvvGIoravNrbvTR1kc36eHs4458juwIAXt2ciYpqc7O/BhER2ScWUdTm1c5EXc8im/X5x/AQeHuokXP+Ij7ddapFXoOIiOwPiyhq04QQfxZRzdhUfjlXlSOeHN0DALA8/ijyS7gAJxERXRuLKGrTzhjLUVRWCUelAmE+Hi32OvdGBKBfgBYlFdV4dROXPCAiomtjEUVtWtplK5U3d1P55ZRKBV4cX7Py/Tf7c5B0ikseEBFR/VhEUZtWe9Ph5lpksz79A3WYNDAQALDwh4MwW7jkARERXR2LKGrT0lpgkc36PD2mBzTOjjh4xoQ1e7Nb5TWJiMg2sYiiNuvypvLWmIkCgI7uasy71GT+2i+Hcb6sslVel4iIbA+LKGqzcs5fRPGFKjg5KNCjBZvK/2pqZGeE+Xig+EIVlv7CJnMiIqobiyhqs2pnoXr4eEDt2HJN5X/l6KDEyxNqmsy/2pPN++oREVGdWERRm9XS60PVZ1CwJ6YMrmkyn/9tGlcyJyKiK7CIojbrz9u96GR5/WfH9ISXuxrH8kvx7vbjsuRARERtF4soapNaY6Xya9G6OuGFO3sBAN7ZdhzH8ktkyYOIiNomFlHUJp0uugjjxSqoHJTo7uMuWx7jwn1xS5g3Ks0WPPdtOixcO4qIiC5hEUVtUu0sVJhv6zaV/5VCocDLE/rAVeWAPSeL8BXXjiIioktYRFGblJpbDKD1Ftmsj7/ORbpB8X9+zsDpogsyZ0RERG0Biyhqk9JrF9lsA0UUAEwfGoxBwR1QVmnG01+n8rQeERGxiKK2RwghXZnXFmaiAMBBqcCy+/rBxckBCScK8dnuU3KnREREMmMRRW1OdtEFmMqroXJUoru+9VYqv5agjm6YPzYMALBkUyZOFpTJnBEREcmJRRS1OamXZqF6+nhA5di2/oj+X2QQhnbtiItVZjy5/gDMPK1HRNRuta1PKCJctlJ5K910uDGUSgWW3tsX7mpH7Dt1Hh/uPCF3SkREJBMWUdTm/LlSedsrogAgoIMrnh/XEwDw2i+HpSZ4IiJqX1hEUZtisQipKJHrdi8NMWlQIG7tpUeVWeDRNcm4UFktd0pERNTKWERRm3Kq6AJKKmqaykP18q1Ufi0KhQKv3tMXeo0aJ86V4aWfDsmdEhERtTIWUdSmpOYUAwB6+Wrg5NC2/3h6uqnwxqT+UCiANXtPY2PaWblTIiKiVtS2P6Wo3UmX+abDjTW0qxceHtkVAPDsN6nILb4oc0ZERNRaWERRm1K7vEFbvDLvap64tTv6B+pgKq/G42uSUW22yJ0SERG1AhZR1GZYLAIHz5gAAH1tqIhyclBi+eQBcFc7Yu/J83hty2G5UyIiolbAIorajKzCMpRWVMPZSYlundpuU3ldOnd0xav39AUAvLfjBLYcNMicERERtTQWUdRm1PZD9fLVwLGNN5XXZVxfX8y4MRgAMG/9AZwq5G1hiIjsme19UpHdSm3ji2w2xPzbeiIiqANKyqvx8Of7UV5lljslIiJqISyiqM3483YvOnkTuQ4qRyVW/O0GdHRT4dBZExb9cFDulIiIqIWwiKI2wWIROGhjyxtcjY/WGcunDIBSAazddxpr9mTLnRIREbUAFlHUJpwoKENZpRkuTg7o2slN7nSu243dvDBvdA8AwIIf0rHvZJHMGRERUXNjEUVtQlpuMQCgl59tNpXX5V83dcXYcB9UmQX++XkSF+IkIrIz9vFpRTbPHprK/0qhUGDZff3Q01eDgtJKPPjJPt6omIjIjrCIojbB1m730lCuKke8Py1CajR/cv0BCCHkTouIiJqB7EXUihUrEBwcDGdnZ0RGRmLPnj31xq9fvx5hYWFwdnZGeHg4Nm7caLVfCIGFCxfC19cXLi4uiI6OxtGjR61iXnnlFQwdOhSurq7Q6XR1vk52djbGjRsHV1dXeHt746mnnkJ1NWcRWoLZIpCea3srlTdUQAdXrLw/Ak4OCmxMM2B5/DG5UyIiomYgaxG1du1azJ07F4sWLcL+/fvRr18/xMTEID8/v874Xbt2YcqUKZg5cyaSk5MxYcIETJgwAenp6VLM0qVLsXz5cqxcuRKJiYlwc3NDTEwMysvLpZjKykrcd999ePjhh+t8HbPZjHHjxqGyshK7du3CJ598gtWrV2PhwoXN+wsgAMCJc6W4WGWGq8oBXWxspfKGGhTsiZfH9wEAvPHrEfx44IzMGRER0XUTMho8eLCYPXu29LPZbBZ+fn4iNja2zviJEyeKcePGWW2LjIwUDz30kBBCCIvFInx8fMRrr70m7S8uLhZqtVp89dVXVzzfxx9/LLRa7RXbN27cKJRKpTAYDNK2d999V2g0GlFRUdHg8RmNRgFAGI3GBh/THn2977QIemaDuPfdP+ROpcW9+ONBEfTMBhH63Eax+3iB3OkQEVEdGvr5LdtMVGVlJZKSkhAdHS1tUyqViI6ORkJCQp3HJCQkWMUDQExMjBSflZUFg8FgFaPVahEZGXnV57za64SHh0Ov11u9jslkwsGDV188saKiAiaTyepB11a7yGYfO+uHqsu/x/VETG89Ks0WzPosCcfyS+VOiYiImki2IqqgoABms9mqUAEAvV4Pg6Hum7caDIZ642u/NuY5G/M6l79GXWJjY6HVaqVHYGBgg1+zPastouyxH+qvHJQKvDlpAAZ01sF4sQoPfLwH50oq5E6LiIiaQPbGcnsyf/58GI1G6XH69Gm5U2rzqs0WHDpTM2MX7q+TN5lW4qJywAfTBiKooytyzl/EzE/2cukDIiIbJFsR5eXlBQcHB+Tl5Vltz8vLg4+PT53H+Pj41Btf+7Uxz9mY17n8NeqiVquh0WisHlS/4+fKcLHKDDeVA7p42f5K5Q3V0V2N1TMGo4OrE1JzjHjky2RUmS1yp0VERI0gWxGlUqkQERGB+Ph4aZvFYkF8fDyioqLqPCYqKsoqHgDi4uKk+JCQEPj4+FjFmEwmJCYmXvU5r/Y6aWlpVlcJxsXFQaPRoFevXg1+Hrq22lN5vf21UCoVMmfTukK83PDB9EFQOyoRn5mPZ75OhcXCNaSIiGyFrKfz5s6di/fffx+ffPIJMjIy8PDDD6OsrAwzZswAAEybNg3z58+X4h977DFs3rwZr7/+OjIzM/HCCy9g3759mDNnDoCaFaIff/xxLF68GD/++CPS0tIwbdo0+Pn5YcKECdLzZGdnIyUlBdnZ2TCbzUhJSUFKSgpKS2uafEePHo1evXrh/vvvx4EDB/DLL7/g+eefx+zZs6FWq1vvF9QOpOUUA7C/RTYbKiKoA96ZegMclAp8m5yLlzYc4mKcRES2onUuFry6t956S3Tu3FmoVCoxePBgsXv3bmnfyJEjxfTp063i161bJ7p37y5UKpXo3bu3+Pnnn632WywWsWDBAqHX64VarRajRo0Shw8ftoqZPn26AHDFY9u2bVLMyZMnxW233SZcXFyEl5eXmDdvnqiqqmrU2LjEwbXdtWKnCHpmg/g+OUfuVGT13f4cEfzsBhH0zAbx3y2Hr30AERG1mIZ+fiuE4H97W4rJZIJWq4XRaGR/VB2qzRb0eeEXlFdZED9vJLra6UKbDfVpwkks/KFmCY2Ft/fC34eFyJwREVH71NDPb16dR7I5dq4U5VUWuKsdEdKx/TSVX820qGDMu7U7AOClDYfwdVKOzBkREVF9WESRbFJzLjWV+2naXVP51cy5pRv+cWkG6umvD+CHlFyZMyIioqthEUWySctpP4tsNpRCocC/x/XElMGdYRHAE2tTeJ89IqI2ikUUyaY93e6lMRQKBV6Z0AeTBgZKhdSGVBZSRERtDYsokkWV2YJDZ2tWKu8boJM3mTZIqVQg9u5w3BcRALNF4LE1KdiYdlbutIiI6DIsokgWR/NKUVltgYfaEUGernKn0yYplQosuacv7rmhppB69KtkbE5nIUVE1FawiCJZpOUWA6g5lcem8qtzUCqw9N6+uHuAP6otArO/TGazORFRG8EiimRR2w8Vzqbya3JQKvDaff2kGanH16bgy8RsudMiImr3WESRLGqvzGuvt3tpLAelAq/d2xf3DwmCEMBz36Xhg99PyJ0WEVG7xiKKWl1ltQUZhhIAXN6gMZRKBV4a3xsPjewCAFj8cwb+9+tR3muPiEgmLKKo1R3JK0FltQUaZ0d0ZlN5oygUCjw7JgxPjq5Z2fyNX4/gPxszYLGwkCIiam0soqjVpV/WD6VQsKm8sRQKBebcEooFt/cCALz/exbmrT+AymqLzJkREbUvLKKo1aVykc1mMXNYCF67ty8clAp8l5yLmZ/sRWlFtdxpERG1GyyiqNXVzkT19dfJm4gduG9gID6YPhAuTg74/WgBpqzajXMlFXKnRUTULrCIolZVWW1B5tmapnJemdc8bu7hjTWzhqCjmwppuUbc8+4unCwokzstIiK7xyKKWtWRvBJUmi3Qujgh0NNF7nTsRr9AHb55eCg6e7oiu+gC7nl3F/Znn5c7LSIiu8YiilpV6mXrQ7GpvHkFe7nhm4eHItxfi8KySkxetZurmxMRtSAWUdSqam/3wpXKW0YnDzXWzBqC6J56VFZb8NiaFPw37gjXkiIiagEsoqhVSbd7YT9Ui3FTO+K9+yPw0IiaRTmXxx/FI18lo7zKLHNmRET2hUUUtZqKajMOG9hU3hoclArMH9sTS+/pC0elAhtSz2LSqt3ILymXOzUiIrvBIopazWFDCarMAjpXJwR0YFN5a5g4KBCfzYyEztUJB04XY/zbf+DA6WK50yIisgssoqjVsKlcHlFdO+L7f92ILp3ccNZYjvveS8C6vaflTouIyOaxiKJWk85+KNkEe7nh+9k3Sg3nT3+Tin9/l8ZbxRARXQcWUdRqamei+vLKPFlonJ2w6v4IzL21OxQK4IvEbExelYA8E/ukiIiagkUUtYryKjOO5F1qKg/QyZtMO6ZUKvDoqFB8NH0QPJwdsT+7GLe/tRN7TxbJnRoRkc1hEUWtItNQgmqLgKebCn5aZ7nTafduDvPGT3OGoYfeA+dKKjB51W68u/04LBauJ0VE1FAsoqhVXL4+FJvK24ZgLzd8+6+huLOfH8wWgVc3Z+Lvn+xFYSlvYExE1BAsoqhVpOUUA2BTeVvjpnbE/yb3x5K7w6F2VGL74XMYu/x3JJ4olDs1IqI2j0UUtYq0XBMA3u6lLVIoFJg8uDN+mHMjunZyQ56pAlPe34234o/CzNN7RERXxSKKWpxVUzlnotqsMB8NfnpkGO65IQAWAbwedwTTP9rDq/eIiK6CRRS1uIyzJpgtAl7uKviyqbxNc1U54vWJ/bDsvn5wcXLAzmMFiHnzN2xOPyt3akREbQ6LKGpxtU3lfdhUbjPujQjAT48MQx9/DYovVOGfn+/Hk+sPoKS8Su7UiIjaDBZR1OKkRTZ5Ks+mdPN2x7cP34h/3dQVCgXwdVIOxi7/Hfu4phQREQAWUdQK0i+biSLbonJU4ukxYVg7Kwr+OhecLrqIie8l4LVfMnnLGCJq91hEUYu6WPlnU3lfrlRuswaHeGLz48OlpvMV247jzrd3SgUyEVF7xCKKWtShsyZYBODlroZeo5Y7HboOHs5OeH1iP7wz9QZ4uqmQaSjB+BV/YNkvh1FRbZY7PSKiVsciilpU7SKbfQPYVG4vxob7Iu6JERjX1xdmi8Db247hjrd24sDpYrlTIyJqVSyiqEXVLrLJfij70tFdjRV/uwHvTr0BXu4qHMkrxV3v/IElmzJRXsVZKSJqH66riCov5yJ8VL+03GIAvDLPXt0W7ostT4zE+P5+sAhg5Y7jGPPmb9h5tEDu1IiIWlyjiyiLxYKXX34Z/v7+cHd3x4kTJwAACxYswIcfftjsCZLtulBZjWP5pQB4uxd75ummwv8mD8B790fA20ONk4UX8H8fJuKJtSko4M2MiciONbqIWrx4MVavXo2lS5dCpVJJ2/v06YMPPvigWZMj23boTE1TubeHGnoNVyq3dzG9ffDrvJGYHhUEhQL4LjkXo17fgbV7s2HhPfiIyA41uoj69NNPsWrVKkydOhUODg7S9n79+iEzM7PRCaxYsQLBwcFwdnZGZGQk9uzZU2/8+vXrERYWBmdnZ4SHh2Pjxo1W+4UQWLhwIXx9feHi4oLo6GgcPXrUKqaoqAhTp06FRqOBTqfDzJkzUVpaahXzyy+/YMiQIfDw8ECnTp1wzz334OTJk40eX3tWu1J5X85CtRsaZye8OL4PvvvXjejlq4HxYhWe+SYNk1ftxtFLS10QEdmLRhdRubm56Nat2xXbLRYLqqoad0uItWvXYu7cuVi0aBH279+Pfv36ISYmBvn5+XXG79q1C1OmTMHMmTORnJyMCRMmYMKECUhPT5dili5diuXLl2PlypVITEyEm5sbYmJirPq3pk6dioMHDyIuLg4bNmzAb7/9hlmzZkn7s7KyMH78eNxyyy1ISUnBL7/8goKCAtx9992NGl97l5bDRTbbq/6BOvw450Y8P64nXJwcsOdkEcYu/x2xGzNQWlEtd3pERM1DNNINN9wgPvvsMyGEEO7u7uL48eNCCCFefPFFMWzYsEY91+DBg8Xs2bOln81ms/Dz8xOxsbF1xk+cOFGMGzfOaltkZKR46KGHhBBCWCwW4ePjI1577TVpf3FxsVCr1eKrr74SQghx6NAhAUDs3btXitm0aZNQKBQiNzdXCCHE+vXrhaOjozCbzVLMjz/+KBQKhaisrGzw+IxGowAgjEZjg4+xJ9GvbxdBz2wQ8RkGuVMhGeWcvyBmrt4jgp7ZIIKe2SAGLo4T3ySdFmazRe7UiIjq1NDP70bPRC1cuBBz5szBq6++CovFgm+//RYPPvggXnnlFSxcuLDBz1NZWYmkpCRER0dL25RKJaKjo5GQkFDnMQkJCVbxABATEyPFZ2VlwWAwWMVotVpERkZKMQkJCdDpdBg4cKAUEx0dDaVSicTERABAREQElEolPv74Y5jNZhiNRnz22WeIjo6Gk5PTVcdUUVEBk8lk9WivyiqqcexczSlSzkS1b/46F3wwfRA+emAggju64lxJBeauO4B7V+6SZiuJiGxRo4uo8ePH46effsKvv/4KNzc3LFy4EBkZGfjpp59w6623Nvh5CgoKYDabodfrrbbr9XoYDIY6jzEYDPXG1369Voy3t7fVfkdHR3h6ekoxISEh2LJlC5577jmo1WrodDrk5ORg3bp19Y4pNjYWWq1WegQGBtYbb88OnTVBCMBH4wxvDzaVE3BLmB6/PDECz4wJg6vKAfuzi3Hnip149ptUXsVHRDapSetEDR8+HHFxccjPz8eFCxewc+dOjB49urlzk43BYMCDDz6I6dOnY+/evdixYwdUKhXuvfdeCHH1q4zmz58Po9EoPU6fPt2KWbctqeyHojqoHR3w8E1dse3Jm3DXAH8IAazZexo3L9uOD3dm8abGRGRTGl1EdenSBYWFhVdsLy4uRpcuXRr8PF5eXnBwcEBeXp7V9ry8PPj4+NR5jI+PT73xtV+vFfPXxvXq6moUFRVJMStWrIBWq8XSpUsxYMAAjBgxAp9//jni4+OlU351UavV0Gg0Vo/26vLbvRD9lV7jjDcm9cfX/4xCbz8NSsqr8fKGQ7j1jR34OfVsvf9ZISJqKxpdRJ08eRJm85W3daioqEBubm6Dn0elUiEiIgLx8fHSNovFgvj4eERFRdV5TFRUlFU8AMTFxUnxISEh8PHxsYoxmUxITEyUYqKiolBcXIykpCQpZuvWrbBYLIiMjAQAXLhwAUql9a+mdjkHi4X/U26I2uUNwjkTRfUYGOyJH+cMQ+zd4fByV+NU4QXM/nI/7n53F/adLJI7PSKiejk2NPDHH3+Uvv/ll1+g1f754Wg2mxEfH4/g4OBGvfjcuXMxffp0DBw4EIMHD8abb76JsrIyzJgxAwAwbdo0+Pv7IzY2FgDw2GOPYeTIkXj99dcxbtw4rFmzBvv27cOqVasAAAqFAo8//jgWL16M0NBQhISEYMGCBfDz88OECRMAAD179sSYMWPw4IMPYuXKlaiqqsKcOXMwefJk+Pn5AQDGjRuHN954Ay+99BKmTJmCkpISPPfccwgKCsKAAQMaNcb2qLSiGicKygDwdB5dm4NSgSmDO+POfn5Y9dsJrPrtBJKzi3HvygTE9NbjmTFh6NLJXe40iYiu1NDL/RQKhVAoFEKpVErf1z5UKpXo3r27+Omnnxp9GeFbb70lOnfuLFQqlRg8eLDYvXu3tG/kyJFi+vTpVvHr1q0T3bt3FyqVSvTu3Vv8/PPPVvstFotYsGCB0Ov1Qq1Wi1GjRonDhw9bxRQWFoopU6YId3d3odFoxIwZM0RJSYlVzFdffSUGDBgg3NzcRKdOncSdd94pMjIyGjW29rrEwe7jBSLomQ1iyH9+lTsVskF5xovi2W8OiJBna5ZE6Dr/Z7Hw+zSRbyqXOzUiaica+vmtEKJxzQchISHYu3cvvLy8WqaqsyMmkwlarRZGo7Fd9Ud98PsJLP45A6N76bFq2sBrH0BUhyN5JViyKRNbM2t6GF2cHPDAjcF4aEQX6FxV1ziaiKjpGvr53eieqKysLBZQVC/2Q1Fz6K73wEcPDMKX/4hEv0AdLlaZ8e724xj+6jb879ejXPmciGTX4J6oy5WVlWHHjh3Izs5GZWWl1b5HH320WRIj21W7gGI4r8yjZjC0mxe+79oRv2bk4/Uth5FpKMEbvx7B6l1ZePimrpgWFQxnJ4drPxERUTNr9Om85ORkjB07FhcuXEBZWRk8PT1RUFAAV1dXeHt748SJEy2Vq81pj6fzSsqrEP7CFgBA0vPR6OiuljkjsicWi8DPaWfxRtwR6eIFbw815tzSDRMHBrKYIqJm0WKn85544gnccccdOH/+PFxcXLB7926cOnUKERERWLZs2XUlTbYvPbfmVjf+OhcWUNTslEoF7ujnhy1PjMDSe/vCX+eC/JIKLPzhIEa+tg0f7szCxcorl2AhImoJjS6iUlJSMG/ePCiVSjg4OKCiogKBgYFYunQpnnvuuZbIkWxIOvuhqBU4OigxcWAgtj15E14e3xu+WmfkmSrw8oZDGL50K1buOM6eKSJqcY0uopycnKSFKL29vZGdnQ2g5ka/7fk2J1QjNZf9UNR6VI5K3B8VjO1P3YT/3BWOgA4uKCitxJJNmRj26la8FX8UpvIqudMkIjvV6MbyAQMGYO/evQgNDcXIkSOxcOFCFBQU4LPPPkOfPn1aIkeyIZyJIjmoHR3wt8jOuG9gAH5IOYMV244hq6AMr8cdwarfT+CBocGYcWMIPN24NAIRNZ9GN5bv27cPJSUluPnmm5Gfn49p06Zh165dCA0NxYcffoj+/fu3UKq2p701lpvKq9D3UlN58oJb0YEfWCQTs0VgQ+oZvL31GI7mlwIAnJ2UuC8iEP8YHoKgjm4yZ0hEbVlDP78bXURRw7W3ImrX8QL87f1EBHRwwc5nbpE7HSJYLAK/HDRgxfZj0kUPSgVwWx9fzBrRBf0CdfImSERtUotdnXc1+/fvx+23395cT0c2SFofiqfyqI1QKhW4LdwXP80Zhi8fjMTI7p1gEcDPaWcxfsUfmPReArZm5sFi4f8liajxGtUT9csvvyAuLg4qlQr/+Mc/0KVLF2RmZuLZZ5/FTz/9hJiYmJbKk2wAm8qprVIoFBja1QtDu3oh02DCqt9O4MeUM0jMKkJiVhG6693x4PAuuLO/H9SOXGuKiBqmwTNRH374IW677TasXr0ar776KoYMGYLPP/8cUVFR8PHxQXp6OjZu3NiSuVIbx6ZysgVhPhr8d2J//P7MzZg1ogvc1Y44kleKp75OxY1LtuK/Ww4jz1Qud5pEZAMa3BPVt29f3H///XjqqafwzTff4L777sOQIUOwbt06BAQEtHSeNqk99UQZL1Sh30s1TeUpC2/lDWLJZpjKq/BVYjZW7zqJs8aa4slRqcDYcF88cGMwBgTqoFAoZM6SiFpTszeWu7m54eDBgwgODoYQAmq1Gtu2bcONN97YbEnbm/ZURP1xrABTP0hEoKcLfn+aTeVke6rNFmw5lIfVf5zEnpNF0vZ+AVo8cGMwxob78lQfUTvR7I3lFy9ehKurK4Ca/gK1Wg1fX9/rz5TsQuqlpvK+/jp5EyFqIkcHJcaG+2LdP6Ow4ZFhuC8iACpHJQ7kGPHE2gO4cck2vBF3BPk81UdElzSqsfyDDz6Au7s7AKC6uhqrV6+Gl5eXVcyjjz7afNmRzUhnUznZkT7+Wrx2Xz88e1sY1uw9jc8STsFgKsf/4o/i7W3HEN3TG3+LDMLwbl5QKnmqj6i9avDpvODg4Gv2BSgUCpw4caJZErMH7el03vClW3G66CK++Eckbuzmde0DiGxIldmCLQfzsHpXFvaePC9tD/R0weRBnTFxYCA6efCG20T2gotttgHtpYgqvlCJ/i/FAQAOLBwNrauTzBkRtZwjeSX4MjEb3+zPQUl5zU2OHZUKxPT2wd8iOyOqS0fOThHZuIZ+fjf63nlEf5V26VReUEdXFlBk97rrPfDCnb3xzJgwbEg9gy/3ZCM5uxg/p53Fz2lnEdzRFVMGd8bdNwRwdorIzrGIouuWxvWhqB1yUTngvoGBuG9gIA6dMeGrPdn4LjkXJwsvIHZTJpb+chg39+iEeyMCcUuYN1SOzXaDCCJqI1hE0XXj7V6ovevlp8HLE/rg2dvC8NOBM1iz9zRSThfj14x8/JqRD083Fcb398N9EYHo5We/p/aJ2hsWUXTd0nhlHhEAwE3tiMmDO2Py4M44ll+C9Uk5+HZ/Ls6VVODjP07i4z9OorefBvdGBGB8f394unFRWiJbxsbyFtQeGsvPl1ViwMs1TeWpL4yGxpk9UUSXqzZb8NvRc/g6KQdxh/JQZa75J9fJQYHonnpMGOCPm3p04kKeRG1IizWWm0ymOrfXLsCpUvF/Vu1J7SxUiJcbCyiiOjg6KHFLmB63hOlxvqwSP6TkYn1SDg6eMWFTugGb0g3QujhhbLgPxvf3x+BgT17dR2QjGl1E6XT130cqICAADzzwABYtWgSlko2U9q62iOrDfiiia+rgpsIDN4bggRtDcOiMCd/uz8GPB84gv6QCX+05ja/2nIav1hl39vPD+P7+6Onrwfv2EbVhjS6iVq9ejX//+9944IEHMHjwYADAnj178Mknn+D555/HuXPnsGzZMqjVajz33HPNnjC1Lak5xQCAviyiiBqll58Gvfx6Yf7Ynkg8UYjvU3KxKd2As8ZyvPfbCbz32wl017tjfH9/3NnPD4GernKnTER/0eieqFGjRuGhhx7CxIkTrbavW7cO7733HuLj4/HZZ5/hlVdeQWZmZrMma2vaQ0/UjUu2Irf4Ir56cAiiunaUOx0im1ZeZcb2w/n4PvkMtmbmo9JskfZFBHXAuHBf3BbuA1+ti4xZEtm/Flux3MXFBampqQgNDbXafvToUfTr1w8XLlxAVlYWevfujQsXLjQtezth70VUYWkFIhb/CgBIe2E0PNgTRdRsjBer8Eu6Ad+n5CLhRCEu/5c6IqgDxob7YiwLKqIW0WKN5YGBgfjwww+xZMkSq+0ffvghAgMDAQCFhYXo0KFDY5+abExtP1QXLzcWUETNTOvihImDAjFxUCDyTOXYmHYWG9POYu/J80g6VfN4ecMh3NBZd6mg8oWfjgUVUWtqdBG1bNky3Hfffdi0aRMGDRoEANi3bx8yMzPx9ddfAwD27t2LSZMmNW+m1OZIi2xyfSiiFqXXOGPGjSGYcWMIDMZybEqvKaj2nTqP/dnF2J9djMU/Z2BAZ92lU36+8GdBRdTimrROVFZWFt577z0cOXIEANCjRw889NBDCA4Obu78bJq9n86b9ek+bDmUh+fH9cQ/hneROx2idifPVI5NaWexMc2AvaeKrE75hftrMbqXHrf21qOHnlf5ETVGi/VEUcPZexEVFRuPs8ZyrJ01BJFd2FROJKc8Uzk2pxvwc9pZ7D1pXVB19nTF6F56jO7tg4igDnDgOlRE9WrRIqq4uBh79uxBfn4+LBaL1b5p06Y1Pls7Zc9F1LmSCgx65VcoFEDaCzFwV/MOQkRtxbmSCmzNzMOWg3n4/VgBKqv//Hfa002FUWHeGN3bB8NDveDsxJXSif6qxYqon376CVOnTkVpaSk0Go3VFLFCoUBRUVHTs7Yz9lxEbcvMx4zVe9G1kxvi590kdzpEdBVlFdX4/eg5bDmYh/jMfBgvVkn7XJwcMDzUC7f20uOmHt7o5KGWMVOitqPFrs6bN28e/v73v+M///kPXF25+Ft7VXtlXt8AnbyJEFG93NSOGNPHF2P6+KLKbMHek0XYcjAPcYfykFt8EVsO5WHLoTwAQL8ALW7q4Y1bwrwR7q/l7WeIrqHRM1Fubm5IS0tDly5sJL4We56J+scn+/BrRh4W3N4LM4eFyJ0OETWSEAKHzpqw5WAetmbmS/8xquXlrsLI7jUF1fDuXrw3JrUrLTYTFRMTg3379rGIaufSpZkoLm9AZIsUCgV6+2nR20+LJ27tjnxTObYfOYdtmfn4/WgBCkor8c3+HHyzPweOSgUigjrgljBv3BzmjVBvd17tR4QmFFHjxo3DU089hUOHDiE8PBxOTtb/O7nzzjubLTlqm/JLymEwlUOhAHr52tcMG1F75a1xxsSBgZg4MBCV1RbsO1WEbZn52JqZj+PnypCYVYTErCLEbsqEv84FI7p3wohQLwzt6gWtK2epqH1q9Ok8pVJ59SdTKGA2m687KXthr6fztmbm4e+r9yHU2x1xc0fKnQ4RtbDswgvYdrimoEo4UWh1tZ9SAfQL1GF4aE1R1S9QByeHq39OENmCFjud99clDaj9Sa1dqdyfp/KI2oPOHV0xfWgwpg8NxsVKMxJOFOD3ozWPY/mlSM4uRnJ2MZbHH4WH2hFRXTti+KWZqqCObnKnT9RiuLgPNRpv90LUfrmoHHBLmB63hOkBAGeKL2Ln0QL8fqwAO4+ew/kLVVZX/HX2dMWwUC8M7+aFIV06ooObSs70iZpVg+Zcly9fjvLycun7+h6NtWLFCgQHB8PZ2RmRkZHYs2dPvfHr169HWFgYnJ2dER4ejo0bN1rtF0Jg4cKF8PX1hYuLC6Kjo3H06FGrmKKiIkydOhUajQY6nQ4zZ85EaWnpFc+zbNkydO/eHWq1Gv7+/njllVcaPT57VHsVD2eiiMhP54KJgwLx1pQBSHr+Vvw0ZxieiumBIV084eSgQHbRBXyZmI2Hv9iPGxbHYez/fsfLGw4hPiMPJeVV134BojasQT1RISEh2LdvHzp27IiQkKtfzq5QKHDixIkGv/jatWsxbdo0rFy5EpGRkXjzzTexfv16HD58GN7e3lfE79q1CyNGjEBsbCxuv/12fPnll3j11Vexf/9+9OnTBwDw6quvIjY2Fp988glCQkKwYMECpKWl4dChQ3B2dgYA3HbbbTh79izee+89VFVVYcaMGRg0aBC+/PJL6bUeffRRbNmyBUuXLkV4eDiKiopQVFSEW2+9tcHjs8eeqDxTOSL/Ew+lAkh/MQauKk5mElHdyiqqkZhViN+OFGDX8QIcybP+z6qDUoE+/lpEdemIoV07YmBwB/6bQm2CTdw7LzIyEoMGDcLbb78NoKbfKjAwEI888gieffbZK+InTZqEsrIybNiwQdo2ZMgQ9O/fHytXroQQAn5+fpg3bx6efPJJAIDRaIRer8fq1asxefJkZGRkoFevXti7dy8GDhwIANi8eTPGjh2LnJwc+Pn5ISMjA3379kV6ejp69OjR5PHZYxH166E8/OPTfeiud8eWJ9hUTkQNd66kArtPFGLX8UIkHC/AycILVvudHBToH6hDVJeOiOrqhQGddbwtDcmixRrLm0tlZSWSkpIwf/58aZtSqUR0dDQSEhLqPCYhIQFz58612hYTE4Pvv/8eAJCVlQWDwYDo6Ghpv1arRWRkJBISEjB58mQkJCRAp9NJBRQAREdHQ6lUIjExEXfddRd++ukndOnSBRs2bMCYMWMghEB0dDSWLl0KT0/Pq46poqICFRUV0s8mk6lRvxNbkCqdytPJmwgR2ZxOHmrc0c8Pd/TzA1DTT5VwvBAJJwqRcLwQucUXsffkeew9eR7Ltx6DylGJ/oE6RIZ4YnCIJ27o3AFuvE8ntSGN/tNoNpuxevVqxMfH13kD4q1btzboeQoKCmA2m6HX66226/V6ZGZm1nmMwWCoM95gMEj7a7fVF/PXU4WOjo7w9PSUYk6cOIFTp05h/fr1+PTTT2E2m/HEE0/g3nvvrXd8sbGxePHFF681dJvGRTaJqLn46VxwT0QA7okIgBACp4suYtfxAiRcmq06V1KBPVlF2JNVc09WB6UCffw0GBRcU1QNCvZkozrJqtFF1GOPPYbVq1dj3Lhx6NOnj12uWmuxWFBRUYFPP/0U3bt3BwB8+OGHiIiIwOHDh696im/+/PlWM2UmkwmBgYGtknNrEEJIyxv0YVM5ETUjhUKBzh1d0bljZ0we3BlCCBw/V4a9J4uw99JCn7nFF3Egx4gDOUZ8sDMLANBd7y4VVYNDPOGrdZF5JNSeNLqIWrNmDdatW4exY8de1wt7eXnBwcEBeXl5Vtvz8vLg4+NT5zE+Pj71xtd+zcvLg6+vr1VM//79pZj8/Hyr56iurkZRUZF0vK+vLxwdHaUCCgB69uwJAMjOzr5qEaVWq6FW2+9d0PNMFSgorYCDUsGVyomoRSkUCnTzdkc3b3dMGdwZAGpO92UVYc+lwupofimO5NU8vkjMBgAEerpgUJAnbgjqgBs6d0APHw848EbK1EIaXUSpVCp069btul9YpVIhIiIC8fHxmDBhAoCaGaD4+HjMmTOnzmOioqIQHx+Pxx9/XNoWFxeHqKgoADVXEfr4+CA+Pl4qmkwmExITE/Hwww9Lz1FcXIykpCREREQAqDkFabFYEBkZCQC48cYbUV1djePHj6Nr164AgCNHjgAAgoKCrnvstio1pxgAEOrtDhcVmz2JqHX561zgP8AfEwb4AwCKyiqx92TN6b69J4uQnmvE6aKLOF2Ui2+TcwEA7mpH9AvUIqJzB9wQ1AEDAjvwNjXUbBp9dd7rr7+OEydO4O23377uU3lr167F9OnT8d5772Hw4MF48803sW7dOmRmZkKv12PatGnw9/dHbGwsgJolDkaOHIklS5Zg3LhxWLNmDf7zn/9cscTBkiVLrJY4SE1NvWKJg7y8PKxcuVJa4mDgwIHSEgcWiwWDBg2Cu7s73nzzTVgsFsyePRsajQZbtmxp8Pjs7eq8/245jOVbj+G+iAC8dl8/udMhIrJSWlGNpFPnkXTqPJKzzyM5uxilFdVXxIV6u+OGzh0QEdQBNwTp0MXLHUrOVtFlWuzqvJ07d2Lbtm3YtGkTevfufcUNiL/99tsGP9ekSZNw7tw5LFy4EAaDAf3798fmzZulxvDs7Gyre/UNHToUX375JZ5//nk899xzCA0Nxffffy8VUADw9NNPo6ysDLNmzUJxcTGGDRuGzZs3SwUUAHzxxReYM2cORo0aBaVSiXvuucdqoVClUomffvoJjzzyCEaMGAE3NzfcdttteP311xv767Ir0pV5bConojbIXe2Ikd07YWT3TgAAs0XgSF4J9mfXFFb7T53HycILOJpfiqP5pVi77zQAQOvihAGdddJsVXiAFhpnzlbRtTV6JmrGjBn17v/444+vKyF7Yk8zUUIIDHrlVxSUVuK7fw3FgM4d5E6JiKjRCksrsD+7WCqsDpwuRkX1lfeE7dLJDf0DdOgXqEPfAC16+mq4ZlU70iIzUdXV1bj55psxevToqzZ/k306ayxHQWklHJQK9GRTORHZqI7uatzaS49be9Wc8agyW5Bx1iSdBkw5XYyc8xdx4lwZTpwrk3qrnBxq/u3rG6BFvwAd+gfq0KWTO5vW27lGFVGOjo745z//iYyMjJbKh9qo2vvlddd78H9jRGQ3nByU6BugQ98AHWbcWHNbs8LSCqTmGJFyuhipOcU4kGNEUVklUnOMSM0x4nPUXAnopnJAeIAW/QJ16Hdp1spP62yXS/9Q3RrdEzV48GAkJye366vU2qO0nNqVyjkLRUT2raO7GjeHeePmsJqFmYUQyDl/EQdyinHgdDEOnDYiLdeIskozdp8owu4TRdKxXu5q9AvQore/Fn38NOjjr4UvCyu71egi6l//+hfmzZuHnJwcREREwM3NzWp/3759my05ajv+bCrXyZsIEVErUygUCPR0RaCnK27vW3PLmmqzBcfOldYUVTlGHDhdjExDCQpKKxCfmY/4zD/XI/R0U6H3pYKqj58Wffw16OzpysLKDjS6sfzyq+WkJ1EoIISAQqGA2WxutuRsnb00lgshELH4VxSVVeL72Teif6BO7pSIiNqc8iozDp4xIi3HiPQzJqTnGnE0vxRmy5Ufsx7OjjWFlZ+2prjy1yDEiz1WbUWLLXGQlZV1XYmR7cktvoiisko4KhUI8/GQOx0iojbJ2ckBEUGeiAj680b15VVmHDaUIP2MEem5Jhw6Y0SGoQQl5dVXnAp0cXJALz8N+vhp0NtPi15+GnTzdmcfahvW6CKKvVDtTzqbyomImsTZyaGm8fyyGfwqswXH8kuRnmvEwUszVofOmnCh0ixdJVjLQalAFy839PTVIMzXAz19Nejpo4Feo+bpwDag0UVUrUOHDiE7OxuVlZVW2++8887rToraltqbDvflIptERNfNyUFZUwz5anDfpW1mi0BWQRkOnjEiPbdm1irDYELxhSppcdAfD/z5HB1cnWoKKx8Nel4qrjhr1foaXUSdOHECd911F9LS0qReKABSRcyeKPuTxpXKiYhalIPyzxsuj+9fc29AIQTyTBXIOFtTUGWcLUHmWRNOFJTh/IUq7DpeiF3HC62eg7NWravRRdRjjz2GkJAQxMfHIyQkBHv27EFhYSHmzZuHZcuWtUSOJCMhxJ9FlD+LKCKi1qJQKOCjdYaP1llabgGo6bM6ll+KQ2dNyDxbIhVZV5u10ro4obveHaF6D/TQeyBU747ueg94uatlGJV9aXQRlZCQgK1bt8LLywtKpRJKpRLDhg1DbGwsHn30USQnJ7dEniSTnPMXUXyhCk4OCvRgUzkRkeycnRwuXdH3539s65u1Ml6swt6T57H35Hmr5/F0U6H7pYKqtsDqrneHzlXV2kOyWY0uosxmMzw8aj5Mvby8cObMGfTo0QNBQUE4fPhwsydI8qqdherh4wG1I8+1ExG1RfXNWp04V4aj+SU4kleCw4ZSHM0vQXbRBRSVVV5xhSAAdPJQW81Ydb/0PW/KfKVGF1F9+vTBgQMHEBISgsjISCxduhQqlQqrVq1Cly5dWiJHktGfp/J08iZCRESN5nxp2YReftZrHV2srDkleCSvBEfyS3DEUIIjeaXILb6IcyUVOFdSgZ3HCqyO8dU61xRU3u7o6u2Orp1qerg83drvzFWji6jnn38eZWVlAICXXnoJt99+O4YPH46OHTti7dq1zZ4gyevP272wH4qIyF64XLrv318vGCqtqMbRvBIczaspsA5f+t5gKsdZY81jx5FzVsd0cHVC105/FlVdvd3QtZM7Ajq42v3ioY1esbwuRUVF6NChA7v//8LWVywXQqD/S3EwXqzChkeGWZ1/JyKi9sN4sQpH82pmq47ll+L4uZpHzvmLVz1G5ahESEe3msKqk5s0e9WlkxtcVU1eYalVtNiK5bWOHTuG48ePY8SIEfD09EQz1GLUxpwuugjjxSqoHJTormdTORFRe6V1ccLAYE8MDPa02n6x0owTBaU4fq4Mxy8VV8fyS5FVUIaKagsOX5rN+it/nQu6dKqZserq7Y6uXm4I6eQGvYczlDY0e9XoIqqwsBATJ07Etm3boFAocPToUXTp0gUzZ85Ehw4d8Prrr7dEniSD2n6oMF8PqByvvGciERG1by4qB/T206K3n/WZCrNF4EzxRRw7VyoVV8fzy3D8XCkKyyqRW3wRucUX8ftR674rZyclgju6oUsnN4R4uSHEy/3SVzd0cHVqc2e8Gl1EPfHEE3ByckJ2djZ69uwpbZ80aRLmzp3LIsqOpOYWAwBP4xERUaM4KBUI9HRFoKcrbu7hbbXvfFmldDrw+LkyHMsvxcmCMmQXXUB5lQWZhhJkGq6cvdK6OCHEyw1dLhVVwZe+9vDxgJODPP/Rb3QRtWXLFvzyyy8ICAiw2h4aGopTp041W2Ikv9qm8r4sooiIqJl0cFNhoNuVpwarzBbknL+IrIJSZBVcuPS1DFnnynDGWA7jxSqknC5Gyuliq+OSF9yKDjJdIdjoIqqsrAyurq5XbC8qKoJazdVP7cXlK5VzJoqIiFqak4NSOnX3VxcrzThZWFZTVF32KCqrlK2AAppQRA0fPhyffvopXn75ZQA1C3xZLBYsXboUN998c7MnSPI4VXgBJeXVUDmyqZyIiOTlonKQbtrcljS6iFq6dClGjRqFffv2obKyEk8//TQOHjyIoqIi/PHHHy2RI8mgdhaqpw+byomIiOrS6E/HPn364MiRIxg2bBjGjx+PsrIy3H333UhOTkbXrl1bIkeSgbRSeQBP5REREdWlSetEabVa/Pvf/7balpOTg1mzZmHVqlXNkhjJ68+mcp28iRAREbVRzXaeprCwEB9++GFzPR3JyGIRSGdTORERUb3Y7EJXOFV0ASUV1VA7KhGqd5c7HSIiojaJRRRdITWnGADQ01cj2wJmREREbR0/IekKtafy+rKpnIiI6Koa3Fh+991317u/uLj4enOhNiI1h/1QRERE19LgIkqrrf8DVavVYtq0adedEMnLYhE4eMYEgDNRRERE9WlwEfXxxx+3ZB7URmQVlqG0ohrOTkp068SmciIioqthTxRZqe2H6uWrgSObyomIiK6Kn5JkpbYfKpz9UERERPViEUVWalcqDw/QyZsIERFRG8ciiiRmi8DBM5yJIiIiaggWUSTJKihFWaUZLk4O6NrJTe50iIiI2jQWUSRJq20q92NTORER0bXwk5IkbConIiJqOBZRJOHtXoiIiBqORRQBqGkqT8+tWamcM1FERETXxiKKAAAnzpXiYpUZrioHdOFK5URERNfUJoqoFStWIDg4GM7OzoiMjMSePXvqjV+/fj3CwsLg7OyM8PBwbNy40Wq/EAILFy6Er68vXFxcEB0djaNHj1rFFBUVYerUqdBoNNDpdJg5cyZKS0vrfL1jx47Bw8MDOp3uusbZltX2Q/X208BBqZA5GyIiorZP9iJq7dq1mDt3LhYtWoT9+/ejX79+iImJQX5+fp3xu3btwpQpUzBz5kwkJydjwoQJmDBhAtLT06WYpUuXYvny5Vi5ciUSExPh5uaGmJgYlJeXSzFTp07FwYMHERcXhw0bNuC3337DrFmzrni9qqoqTJkyBcOHD2/+wbchtVfmhfvr5E2EiIjIVgiZDR48WMyePVv62Ww2Cz8/PxEbG1tn/MSJE8W4ceOstkVGRoqHHnpICCGExWIRPj4+4rXXXpP2FxcXC7VaLb766ishhBCHDh0SAMTevXulmE2bNgmFQiFyc3Otnvvpp58W//d//yc+/vhjodVqGzU2o9EoAAij0dio4+Rw9zt/iKBnNohv95+WOxUiIiJZNfTzW9aZqMrKSiQlJSE6OlraplQqER0djYSEhDqPSUhIsIoHgJiYGCk+KysLBoPBKkar1SIyMlKKSUhIgE6nw8CBA6WY6OhoKJVKJCYmStu2bt2K9evXY8WKFQ0aT0VFBUwmk9XDFlSbLTh0prapXCdvMkRERDZC1iKqoKAAZrMZer3earter4fBYKjzGIPBUG987ddrxXh7e1vtd3R0hKenpxRTWFiIBx54AKtXr4ZGo2nQeGJjY6HVaqVHYGBgg46T2/FzZbhYZYabygFdvLhSORERUUPI3hPVVj344IP429/+hhEjRjT4mPnz58NoNEqP06dPt2CGzSc1pxgA0NtfCyWbyomIiBpE1iLKy8sLDg4OyMvLs9qel5cHHx+fOo/x8fGpN77267Vi/tq4Xl1djaKiIilm69atWLZsGRwdHeHo6IiZM2fCaDTC0dERH330UZ25qdVqaDQaq4ctSM/lSuVERESNJWsRpVKpEBERgfj4eGmbxWJBfHw8oqKi6jwmKirKKh4A4uLipPiQkBD4+PhYxZhMJiQmJkoxUVFRKC4uRlJSkhSzdetWWCwWREZGAqjpm0pJSZEeL730Ejw8PJCSkoK77rqreX4BbUQqVyonIiJqNEe5E5g7dy6mT5+OgQMHYvDgwXjzzTdRVlaGGTNmAACmTZsGf39/xMbGAgAee+wxjBw5Eq+//jrGjRuHNWvWYN++fVi1ahUAQKFQ4PHHH8fixYsRGhqKkJAQLFiwAH5+fpgwYQIAoGfPnhgzZgwefPBBrFy5ElVVVZgzZw4mT54MPz8/KeZy+/btg1KpRJ8+fVrpN9M6Lm8q78OZKCIiogaTvYiaNGkSzp07h4ULF8JgMKB///7YvHmz1BienZ0NpfLPCbOhQ4fiyy+/xPPPP4/nnnsOoaGh+P77762Km6effhplZWWYNWsWiouLMWzYMGzevBnOzs5SzBdffIE5c+Zg1KhRUCqVuOeee7B8+fLWG3gbcTS/FBXVFrirHRHSkU3lREREDaUQQgi5k7BXJpMJWq0WRqOxzfZHrdt3Gk9/nYohXTyxZlbdp1CJiIjak4Z+fvPqvHYuLYdN5URERE3BIqqdk273EqCTNxEiIiIbwyKqHasyW3DobO1K5ZyJIiIiagwWUe3Y0bxSVFZb4OHsiCBPV7nTISIisiksotqxtNxiAEAfP65UTkRE1FgsotqxNC6ySURE1GQsotqx2ivzuMgmERFR47GIaqcqqy3IMJQA4EwUERFRU7CIaqeO5JWgstoCjbMjOrOpnIiIqNFYRLVTf64PpYVCwaZyIiKixmIR1U7VFlHshyIiImoaFlHtVG1TeV9/nbyJEBER2SgWUe1QRbUZmQauVE5ERHQ9WES1Q0cMpagyC2hdnBDo6SJ3OkRERDaJRVQ7dPkim2wqJyIiahoWUe2QdLsXnsojIiJqMhZR7ZA0E8UiioiIqMlYRLUzFdVmHL60UjlnooiIiJqORVQ7c9hQgiqzQAdXJwR0YFM5ERFRU7GIamdSL7vpMJvKiYiImo5FVDuTftmVeURERNR0LKLamdqZKC6ySUREdH1YRLUj5VVmHMmraSoPD9DJmwwREZGNYxHVjmQaSlBtEfB0U8FP6yx3OkRERDaNRVQ7kpZTDKDmVB6byomIiK4Pi6h2pHaRTfZDERERXT8WUe2I1FTOK/OIiIiuG4uodqK8yoyj+aUAOBNFRETUHFhEtROHzppgtgh4uavgy6ZyIiKi68Yiqp1Iv6wfik3lRERE149FVDvBRTaJiIiaF4uodkKaieIim0RERM2CRVQ7cLHyspXKORNFRETULFhEtQOHzppgEUAnDzX0GrXc6RAREdkFFlHtAFcqJyIian4sotqBtFwTAJ7KIyIiak4sotqBtNxiACyiiIiImhOLKDt3obIax2pXKuftXoiIiJoNiyg7d+hMTVO5t4caeg1XKiciImouLKLsXO0im305C0VERNSsWETZudpFNvuwH4qIiKhZtYkiasWKFQgODoazszMiIyOxZ8+eeuPXr1+PsLAwODs7Izw8HBs3brTaL4TAwoUL4evrCxcXF0RHR+Po0aNWMUVFRZg6dSo0Gg10Oh1mzpyJ0tJSaf/27dsxfvx4+Pr6ws3NDf3798cXX3zRfINuJam5nIkiIiJqCbIXUWvXrsXcuXOxaNEi7N+/H/369UNMTAzy8/PrjN+1axemTJmCmTNnIjk5GRMmTMCECROQnp4uxSxduhTLly/HypUrkZiYCDc3N8TExKC8vFyKmTp1Kg4ePIi4uDhs2LABv/32G2bNmmX1On379sU333yD1NRUzJgxA9OmTcOGDRta7pfRzMoqqnH8XE1hyJkoIiKi5qUQQgg5E4iMjMSgQYPw9ttvAwAsFgsCAwPxyCOP4Nlnn70iftKkSSgrK7MqZoYMGYL+/ftj5cqVEELAz88P8+bNw5NPPgkAMBqN0Ov1WL16NSZPnoyMjAz06tULe/fuxcCBAwEAmzdvxtixY5GTkwM/P786cx03bhz0ej0++uijBo3NZDJBq9XCaDRCo9E06vfSHPZkFWHiewnw0Thj93OjWv31iYiIbFFDP79lnYmqrKxEUlISoqOjpW1KpRLR0dFISEio85iEhASreACIiYmR4rOysmAwGKxitFotIiMjpZiEhATodDqpgAKA6OhoKJVKJCYmXjVfo9EIT0/Pq+6vqKiAyWSyesgpTbrpMGehiIiImpusRVRBQQHMZjP0er3Vdr1eD4PBUOcxBoOh3vjar9eK8fb2ttrv6OgIT0/Pq77uunXrsHfvXsyYMeOq44mNjYVWq5UegYGBV41tDZff7oWIiIial+w9UbZg27ZtmDFjBt5//3307t37qnHz58+H0WiUHqdPn27FLK/EmSgiIqKWI2sR5eXlBQcHB+Tl5Vltz8vLg4+PT53H+Pj41Btf+/VaMX9tXK+urkZRUdEVr7tjxw7ccccdeOONNzBt2rR6x6NWq6HRaKwecimtqMaJgjIAnIkiIiJqCbIWUSqVChEREYiPj5e2WSwWxMfHIyoqqs5joqKirOIBIC4uTooPCQmBj4+PVYzJZEJiYqIUExUVheLiYiQlJUkxW7duhcViQWRkpLRt+/btGDduHF599VWrK/dswcFcI4QA/LTO8HJXy50OERGR3XGUO4G5c+di+vTpGDhwIAYPHow333wTZWVlUu/RtGnT4O/vj9jYWADAY489hpEjR+L111/HuHHjsGbNGuzbtw+rVq0CACgUCjz++ONYvHgxQkNDERISggULFsDPzw8TJkwAAPTs2RNjxozBgw8+iJUrV6Kqqgpz5szB5MmTpSvztm3bhttvvx2PPfYY7rnnHqlXSqVS1dtc3lakcZFNIiKiliXagLfeekt07txZqFQqMXjwYLF7925p38iRI8X06dOt4tetWye6d+8uVCqV6N27t/j555+t9lssFrFgwQKh1+uFWq0Wo0aNEocPH7aKKSwsFFOmTBHu7u5Co9GIGTNmiJKSEmn/9OnTBYArHiNHjmzwuIxGowAgjEZjw38ZzeTRr/aLoGc2iLfij7T6axMREdmyhn5+y75OlD2Tc52oW5Ztx4mCMqyeMQg39fC+9gFEREQEwEbWiaKWUVJexaZyIiKiFsYiyg6l59Ys8umvc0FHNpUTERG1CBZRdigttxgAZ6GIiIhaEosoO5R2aSaKi2wSERG1HBZRdoi3eyEiImp5LKLsjPFiFU4WXgDAIoqIiKglsYiyMwcvLbIZ0MEFHdxUMmdDRERkv1hE2Znalcr7sh+KiIioRbGIsjOpvN0LERFRq2ARZWfSa2ei/HXyJkJERGTnWETZEeOFKpy61FTex791bzNDRETU3rCIsiPpZ2pmoTp7ukLnyqZyIiKilsQiyo6k5tQUUVzagIiIqOWxiLIjtf1QXKmciIio5bGIsiOpvGceERFRq2ERZSeKL1TidNFFAEAfPxZRRERELY1FlJ2oXWQzqKMrtK5OMmdDRERk/1hE2Qk2lRMREbUuFlF2QmoqZxFFRETUKlhE2QlpJopX5hEREbUKFlF2oKisErnFl5rKORNFRETUKlhE2YHapvIQLzdonNlUTkRE1BpYRNkB9kMRERG1PhZRdiA1pxgAiygiIqLWxCLKDqTnmgCwqZyIiKg1sYiycYWlFVJTeW8/jczZEBERtR8somxcbVN5l05u8GBTORERUathEWXj0rhSORERkSxYRNm4NF6ZR0REJAsWUTaORRQREZE8WETZsHMlFThrLIdCAfRmEUVERNSqWETZsNpFNrt4ucFd7ShzNkRERO0LiygbVnvT4b4BOnkTISIiaodYRNmw2n4o3nSYiIio9bGIsmFpucUAgL5cqZyIiKjVsYiyUfmmcuSZKqBUAL18uVI5ERFRa2MRZaNqT+V17eQONzaVExERtToWUTZKWh+Kp/KIiIhkwSLKRvF2L0RERPJiEWWjamei2FROREQkDxZRNijPVI78ktqmchZRREREcmgTRdSKFSsQHBwMZ2dnREZGYs+ePfXGr1+/HmFhYXB2dkZ4eDg2btxotV8IgYULF8LX1xcuLi6Ijo7G0aNHrWKKioowdepUaDQa6HQ6zJw5E6WlpVYxqampGD58OJydnREYGIilS5c2z4CvU+2pvFBvD7ioHGTOhoiIqH2SvYhau3Yt5s6di0WLFmH//v3o168fYmJikJ+fX2f8rl27MGXKFMycORPJycmYMGECJkyYgPT0dClm6dKlWL58OVauXInExES4ubkhJiYG5eXlUszUqVNx8OBBxMXFYcOGDfjtt98wa9Ysab/JZMLo0aMRFBSEpKQkvPbaa3jhhRewatWqlvtlNFAqF9kkIiKSn5DZ4MGDxezZs6WfzWaz8PPzE7GxsXXGT5w4UYwbN85qW2RkpHjooYeEEEJYLBbh4+MjXnvtNWl/cXGxUKvV4quvvhJCCHHo0CEBQOzdu1eK2bRpk1AoFCI3N1cIIcQ777wjOnToICoqKqSYZ555RvTo0aPBYzMajQKAMBqNDT6mIWZ8vEcEPbNBrP4jq1mfl4iIiBr++S3rTFRlZSWSkpIQHR0tbVMqlYiOjkZCQkKdxyQkJFjFA0BMTIwUn5WVBYPBYBWj1WoRGRkpxSQkJECn02HgwIFSTHR0NJRKJRITE6WYESNGQKVSWb3O4cOHcf78+Tpzq6iogMlksno0NyGEdM88zkQRERHJR9YiqqCgAGazGXq93mq7Xq+HwWCo8xiDwVBvfO3Xa8V4e3tb7Xd0dISnp6dVTF3Pcflr/FVsbCy0Wq30CAwMrHvg18FUXg0XlRIOSgVXKiciIpKR7D1R9mT+/PkwGo3S4/Tp083+GloXJ/z+9C1IXngrm8qJiIhkJGsR5eXlBQcHB+Tl5Vltz8vLg4+PT53H+Pj41Btf+/VaMX9tXK+urkZRUZFVTF3Pcflr/JVarYZGo7F6tBSNs1OLPTcRERFdm6xFlEqlQkREBOLj46VtFosF8fHxiIqKqvOYqKgoq3gAiIuLk+JDQkLg4+NjFWMymZCYmCjFREVFobi4GElJSVLM1q1bYbFYEBkZKcX89ttvqKqqsnqdHj16oEOHDtc5ciIiIrJ5rdPnfnVr1qwRarVarF69Whw6dEjMmjVL6HQ6YTAYhBBC3H///eLZZ5+V4v/44w/h6Ogoli1bJjIyMsSiRYuEk5OTSEtLk2KWLFkidDqd+OGHH0RqaqoYP368CAkJERcvXpRixowZIwYMGCASExPFzp07RWhoqJgyZYq0v7i4WOj1enH//feL9PR0sWbNGuHq6iree++9Bo+tpa7OIyIiopbT0M9v2YsoIYR46623ROfOnYVKpRKDBw8Wu3fvlvaNHDlSTJ8+3Sp+3bp1onv37kKlUonevXuLn3/+2Wq/xWIRCxYsEHq9XqjVajFq1Chx+PBhq5jCwkIxZcoU4e7uLjQajZgxY4YoKSmxijlw4IAYNmyYUKvVwt/fXyxZsqRR42IRRUREZHsa+vmtEEIIeefC7JfJZIJWq4XRaGzR/igiIiJqPg39/ObVeURERERNwCKKiIiIqAlYRBERERE1AYsoIiIioiZgEUVERETUBCyiiIiIiJqARRQRERFRE7CIIiIiImoCFlFERERETeAodwL2rHYxeJPJJHMmRERE1FC1n9vXuqkLi6gWVFJSAgAIDAyUORMiIiJqrJKSEmi12qvu573zWpDFYsGZM2fg4eEBhULRbM9rMpkQGBiI06dP2+U9+ex9fID9j9HexwfY/xg5Pttn72NsyfEJIVBSUgI/Pz8olVfvfOJMVAtSKpUICAhosefXaDR2+Rejlr2PD7D/Mdr7+AD7HyPHZ/vsfYwtNb76ZqBqsbGciIiIqAlYRBERERE1AYsoG6RWq7Fo0SKo1Wq5U2kR9j4+wP7HaO/jA+x/jByf7bP3MbaF8bGxnIiIiKgJOBNFRERE1AQsooiIiIiagEUUERERUROwiCIiIiJqAhZRNmjFihUIDg6Gs7MzIiMjsWfPHrlTusILL7wAhUJh9QgLC5P2l5eXY/bs2ejYsSPc3d1xzz33IC8vz+o5srOzMW7cOLi6usLb2xtPPfUUqqurrWK2b9+OG264AWq1Gt26dcPq1atbZDy//fYb7rjjDvj5+UGhUOD777+32i+EwMKFC+Hr6wsXFxdER0fj6NGjVjFFRUWYOnUqNBoNdDodZs6cidLSUquY1NRUDB8+HM7OzggMDMTSpUuvyGX9+vUICwuDs7MzwsPDsXHjxlYZ4wMPPHDFezpmzBibGWNsbCwGDRoEDw8PeHt7Y8KECTh8+LBVTGv+uWzuv8cNGd9NN910xXv4z3/+0ybG9+6776Jv377SwopRUVHYtGmTtN+W37uGjtGW37+6LFmyBAqFAo8//ri0zebeR0E2Zc2aNUKlUomPPvpIHDx4UDz44INCp9OJvLw8uVOzsmjRItG7d29x9uxZ6XHu3Dlp/z//+U8RGBgo4uPjxb59+8SQIUPE0KFDpf3V1dWiT58+Ijo6WiQnJ4uNGzcKLy8vMX/+fCnmxIkTwtXVVcydO1ccOnRIvPXWW8LBwUFs3ry52cezceNG8e9//1t8++23AoD47rvvrPYvWbJEaLVa8f3334sDBw6IO++8U4SEhIiLFy9KMWPGjBH9+vUTu3fvFr///rvo1q2bmDJlirTfaDQKvV4vpk6dKtLT08VXX30lXFxcxHvvvSfF/PHHH8LBwUEsXbpUHDp0SDz//PPCyclJpKWltfgYp0+fLsaMGWP1nhYVFVnFtOUxxsTEiI8//likp6eLlJQUMXbsWNG5c2dRWloqxbTWn8uW+HvckPGNHDlSPPjgg1bvodFotInx/fjjj+Lnn38WR44cEYcPHxbPPfeccHJyEunp6UII237vGjpGW37//mrPnj0iODhY9O3bVzz22GPSdlt7H1lE2ZjBgweL2bNnSz+bzWbh5+cnYmNjZczqSosWLRL9+vWrc19xcbFwcnIS69evl7ZlZGQIACIhIUEIUfOBrlQqhcFgkGLeffddodFoREVFhRBCiKefflr07t3b6rknTZokYmJimnk01v5aYFgsFuHj4yNee+01aVtxcbFQq9Xiq6++EkIIcejQIQFA7N27V4rZtGmTUCgUIjc3VwghxDvvvCM6dOggjU8IIZ555hnRo0cP6eeJEyeKcePGWeUTGRkpHnrooRYdoxA1RdT48eOveoytjTE/P18AEDt27BBCtO6fy9b4e/zX8QlR8yF8+QfWX9nS+IQQokOHDuKDDz6wu/eurjEKYT/vX0lJiQgNDRVxcXFWY7LF95Gn82xIZWUlkpKSEB0dLW1TKpWIjo5GQkKCjJnV7ejRo/Dz80OXLl0wdepUZGdnAwCSkpJQVVVlNY6wsDB07txZGkdCQgLCw8Oh1+ulmJiYGJhMJhw8eFCKufw5amNa+3eRlZUFg8FglYtWq0VkZKTVeHQ6HQYOHCjFREdHQ6lUIjExUYoZMWIEVCqVFBMTE4PDhw/j/PnzUoycY96+fTu8vb3Ro0cPPPzwwygsLJT22doYjUYjAMDT0xNA6/25bK2/x38dX60vvvgCXl5e6NOnD+bPn48LFy5I+2xlfGazGWvWrEFZWRmioqLs7r2ra4y17OH9mz17NsaNG3dFHrb4PvIGxDakoKAAZrPZ6g8PAOj1emRmZsqUVd0iIyOxevVq9OjRA2fPnsWLL76I4cOHIz09HQaDASqVCjqdzuoYvV4Pg8EAADAYDHWOs3ZffTEmkwkXL16Ei4tLC43OWm0+deVyea7e3t5W+x0dHeHp6WkVExIScsVz1O7r0KHDVcdc+xwtacyYMbj77rsREhKC48eP47nnnsNtt92GhIQEODg42NQYLRYLHn/8cdx4443o06eP9Pqt8efy/PnzLf73uK7xAcDf/vY3BAUFwc/PD6mpqXjmmWdw+PBhfPvttzYxvrS0NERFRaG8vBzu7u747rvv0KtXL6SkpNjNe3e1MQK2//4BwJo1a7B//37s3bv3in22+HeQRRS1iNtuu036vm/fvoiMjERQUBDWrVvXasUNNa/JkydL34eHh6Nv377o2rUrtm/fjlGjRsmYWePNnj0b6enp2Llzp9yptIirjW/WrFnS9+Hh4fD19cWoUaNw/PhxdO3atbXTbLQePXogJSUFRqMRX3/9NaZPn44dO3bInVazutoYe/XqZfPv3+nTp/HYY48hLi4Ozs7OcqfTLHg6z4Z4eXnBwcHhiisV8vLy4OPjI1NWDaPT6dC9e3ccO3YMPj4+qKysRHFxsVXM5ePw8fGpc5y1++qL0Wg0rVqo1eZT3/vi4+OD/Px8q/3V1dUoKipqljHL8f536dIFXl5eOHbsmJSbLYxxzpw52LBhA7Zt24aAgABpe2v9uWzpv8dXG19dIiMjAcDqPWzL41OpVOjWrRsiIiIQGxuLfv364X//+5/dvHf1jbEutvb+JSUlIT8/HzfccAMcHR3h6OiIHTt2YPny5XB0dIRer7e595FFlA1RqVSIiIhAfHy8tM1isSA+Pt7qnHlbVFpaiuPHj8PX1xcRERFwcnKyGsfhw4eRnZ0tjSMqKgppaWlWH8pxcXHQaDTS1HZUVJTVc9TGtPbvIiQkBD4+Pla5mEwmJCYmWo2nuLgYSUlJUszWrVthsVikfwijoqLw22+/oaqqSoqJi4tDjx490KFDBymmLYwZAHJyclBYWAhfX18pt7Y8RiEE5syZg++++w5bt2694rRia/25bKm/x9caX11SUlIAwOo9bKvjq4vFYkFFRYXNv3cNGWNdbO39GzVqFNLS0pCSkiI9Bg4ciKlTp0rf29z72Kg2dJLdmjVrhFqtFqtXrxaHDh0Ss2bNEjqdzupKhbZg3rx5Yvv27SIrK0v88ccfIjo6Wnh5eYn8/HwhRM1lrJ07dxZbt24V+/btE1FRUSIqKko6vvYy1tGjR4uUlBSxefNm0alTpzovY33qqadERkaGWLFiRYstcVBSUiKSk5NFcnKyACD++9//iuTkZHHq1CkhRM0SBzqdTvzwww8iNTVVjB8/vs4lDgYMGCASExPFzp07RWhoqNXl/8XFxUKv14v7779fpKenizVr1ghXV9crLv93dHQUy5YtExkZGWLRokXNtsRBfWMsKSkRTz75pEhISBBZWVni119/FTfccIMIDQ0V5eXlNjHGhx9+WGi1WrF9+3arS8QvXLggxbTWn8uW+Ht8rfEdO3ZMvPTSS2Lfvn0iKytL/PDDD6JLly5ixIgRNjG+Z599VuzYsUNkZWWJ1NRU8eyzzwqFQiG2bNkihLDt964hY7T19+9q/nrFoa29jyyibNBbb70lOnfuLFQqlRg8eLDYvXu33CldYdKkScLX11eoVCrh7+8vJk2aJI4dOybtv3jxovjXv/4lOnToIFxdXcVdd90lzp49a/UcJ0+eFLfddptwcXERXl5eYt68eaKqqsoqZtu2baJ///5CpVKJLl26iI8//rhFxrNt2zYB4IrH9OnThRA1yxwsWLBA6PV6oVarxahRo8Thw4etnqOwsFBMmTJFuLu7C41GI2bMmCFKSkqsYg4cOCCGDRsm1Gq18Pf3F0uWLLkil3Xr1onu3bsLlUolevfuLX7++ecWH+OFCxfE6NGjRadOnYSTk5MICgoSDz744BX/4LTlMdY1NgBWf2Za889lc/89vtb4srOzxYgRI4Snp6dQq9WiW7du4qmnnrJaZ6gtj+/vf/+7CAoKEiqVSnTq1EmMGjVKKqCEsO33riFjtPX372r+WkTZ2vuoEEKIxs1dERERERF7ooiIiIiagEUUERERUROwiCIiIiJqAhZRRERERE3AIoqIiIioCVhEERERETUBiygiIiKiJmARRURERNQELKKIiAAEBwfjzTfflDsNIrIhLKKIyKYoFIp6Hy+88EKTnnfv3r2YNWvWdeWWlZWFv/3tb/Dz84OzszMCAgIwfvx4ZGZmAgBOnjwJhUIh3TiWiGybo9wJEBE1xtmzZ6Xv165di4ULF+Lw4cPSNnd3d+l7IQTMZjMcHa/9T12nTp2uK6+qqirceuut6NGjB7799lv4+voiJycHmzZtQnFx8XU9NxG1TZyJIiKb4uPjIz20Wi0UCoX0c2ZmJjw8PLBp0yZERERArVZj586dOH78OMaPHw+9Xg93d3cMGjQIv/76q9Xz/vV0nkKhwAcffIC77roLrq6uCA0NxY8//njVvA4ePIjjx4/jnXfewZAhQxAUFIQbb7wRixcvxpAhQwAAISEhAIABAwZAoVDgpptuko7/4IMP0LNnTzg7OyMsLAzvvPOOtK92BmvNmjUYOnQonJ2d0adPH+zYsaMZfqNE1FQsoojI7jz77LNYsmQJMjIy0LdvX5SWlmLs2LGIj49HcnIyxowZgzvuuAPZ2dn1Ps+LL76IiRMnIjU1FWPHjsXUqVNRVFRUZ2ynTp2gVCrx9ddfw2w21xmzZ88eAMCvv/6Ks2fP4ttvvwUAfPHFF1i4cCFeeeUVZGRk4D//+Q8WLFiATz75xOr4p556CvPmzUNycjKioqJwxx13oLCwsLG/HiJqLoKIyEZ9/PHHQqvVSj9v27ZNABDff//9NY/t3bu3eOutt6Sfg4KCxBtvvCH9DEA8//zz0s+lpaUCgNi0adNVn/Ptt98Wrq6uwsPDQ9x8883ipZdeEsePH5f2Z2VlCQAiOTnZ6riuXbuKL7/80mrbyy+/LKKioqyOW7JkibS/qqpKBAQEiFdfffWaYyWilsGZKCKyOwMHDrT6ubS0FE8++SR69uwJnU4Hd3d3ZGRkXHMmqm/fvtL3bm5u0Gg0yM/Pv2r87NmzYTAY8MUXXyAqKgrr169H7969ERcXd9VjysrKcPz4ccycORPu7u7SY/HixTh+/LhVbFRUlPS9o6MjBg4ciIyMjHrHQEQth43lRGR33NzcrH5+8sknERcXh2XLlqFbt25wcXHBvffei8rKynqfx8nJyepnhUIBi8VS7zEeHh644447cMcdd2Dx4sWIiYnB4sWLceutt9YZX1paCgB4//33ERkZabXPwcGh3tciInlxJoqI7N4ff/yBBx54AHfddRfCw8Ph4+ODkydPtvjrKhQKhIWFoaysDACgUqkAwKpnSq/Xw8/PDydOnEC3bt2sHrWN6LV2794tfV9dXY2kpCT07NmzxcdBRHXjTBQR2b3Q0FB8++23uOOOO6BQKLBgwYJrzig1VkpKChYtWoT7778fvXr1gkqlwo4dO/DRRx/hmWeeAQB4e3vDxcUFmzdvRkBAAJydnaHVavHiiy/i0UcfhVarxZgxY1BRUYF9+/bh/PnzmDt3rvQaK1asQGhoKHr27Ik33ngD58+fx9///vdmHQcRNRyLKCKye//973/x97//HUOHDoWXlxeeeeYZmEymZn2NgIAABAcH48UXX5SWJKj9+YknngBQ08e0fPlyvPTSS1i4cCGGDx+O7du34x//+AdcXV3x2muv4amnnoKbmxvCw8Px+OOPW73GkiVLsGTJEqSkpKBbt2748ccf4eXl1azjIKKGUwghhNxJEBHR1Z08eRIhISFITk5G//795U6HiC5hTxQRERFRE7CIIiIiImoCns4jIiIiagLORBERERE1AYsoIiIioiZgEUVERETUBCyiiIiIiJqARRQRERFRE7CIIiIiImoCFlFERERETcAiioiIiKgJ/h9W6IRxPnJ5gwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')\n",
        "plt.savefig(checkpoint_dir+'learning_rate_plot.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzXq5LWgRN63"
      },
      "source": [
        "Instantiate the optimizer (in this example it's `tf.keras.optimizers.Adam`):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk8vwuN24hafK"
      },
      "source": [
        "With all the components ready, configure the training procedure using `model.compile`, and then run it with `model.fit`:\n",
        "\n",
        "Note: This takes about an hour to train in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save best model"
      ],
      "metadata": {
        "id": "mHaNJztRAUpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_filepath = checkpoint_dir +model_base_name +'.{epoch:02d}-{val_accuracy:.2f}'\n",
        "checkpoint_filepath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vKCmBK7u7ar3",
        "outputId": "dd013d37-0cf2-4938-c9f3-c07e0b8ecc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./Final_Work/ep20_wm6000_b64_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/wm6000ep20_b64_cl_enh_more_dat_bl_tx_w_tw_2h_2l_d06_dff256.{epoch:02d}-{val_accuracy:.2f}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import losses\n",
        "\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath, #checkpoint_filepath define earlier in this notebook\n",
        "        monitor=\"val_loss\", #'val_loss'\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,  # Add this line\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "vZCijhAPEX75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Compile the Model"
      ],
      "metadata": {
        "id": "SG4IWGdfAigm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transformer.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'],\n",
        "    run_eagerly=True)\n"
      ],
      "metadata": {
        "id": "iGOD9UKLAgz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Start Training"
      ],
      "metadata": {
        "id": "qCqXKL-Bzx0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = transformer.fit(train_dataset, epochs=15, validation_data=val_dataset, callbacks=callbacks_list)\n",
        "\n",
        "# Convert the return value into a DataFrame so we can see the train loss\n",
        "# and binary accuracy after every epoch.\n",
        "history = pd.DataFrame(history.history)\n",
        "plot_history(history, checkpoint_dir)\n",
        "history_to_csv(history, num_layers, d_model, num_heads, dff, dropout_rate, model_base_name, load_data, checkpoint_dir, path_to_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "Uzf9O-bRCY7V",
        "outputId": "b2234fc2-4acb-486f-f9db-8e82ac8aa488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 32s 314ms/step - loss: 0.8042 - accuracy: 0.5318 - val_loss: 0.6782 - val_accuracy: 0.6054\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 31s 314ms/step - loss: 0.7594 - accuracy: 0.5413 - val_loss: 0.6731 - val_accuracy: 0.6068\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.7153 - accuracy: 0.5548 - val_loss: 0.6596 - val_accuracy: 0.6209\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 32s 316ms/step - loss: 0.6932 - accuracy: 0.5658 - val_loss: 0.6571 - val_accuracy: 0.6393\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 31s 315ms/step - loss: 0.6787 - accuracy: 0.5757 - val_loss: 0.6411 - val_accuracy: 0.6379\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 31s 314ms/step - loss: 0.6555 - accuracy: 0.6152 - val_loss: 0.6179 - val_accuracy: 0.6605\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 31s 305ms/step - loss: 0.6340 - accuracy: 0.6380 - val_loss: 0.6025 - val_accuracy: 0.6846\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.6643"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-f05a3eab082d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the return value into a DataFrame so we can see the train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and binary accuracy after every epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mrelpath\u001b[0;34m(path, start)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mstart_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mpath_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# Work out how much of the filepath is shared by start and path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mabspath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Memory Clean Up"
      ],
      "metadata": {
        "id": "KvOBNMYM8Egc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del transformer"
      ],
      "metadata": {
        "id": "9kwAONtz8JJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "note = \"resutls are bad for wu 6000, maybe go in the opposite diretion?val_accuracy: 0.7242\""
      ],
      "metadata": {
        "id": "yFyf64HR1I8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add a note to share drive"
      ],
      "metadata": {
        "id": "rZNaCJ8VthFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the directory and file name\n",
        "directory = checkpoint_dir\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "readme_content = f\"\"\"Post Results Note: {note}\n",
        "\n",
        "\"\"\"\n",
        "# path\n",
        "readme_file_path = f'{directory}/note_about_results.txt'\n",
        "\n",
        "# Write the readme content to the file\n",
        "with open(readme_file_path, 'w') as readme_file:\n",
        "    readme_file.write(readme_content)\n",
        "\n",
        "# Print a success message\n",
        "print(f\"The note_about_resultsfile has been successfully written to the '{directory}' directory.\")\n",
        "\n",
        "print(readme_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMlliyVUtW6A",
        "outputId": "bb840fd8-79e7-41d7-e57d-7751c46ec85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The note_about_resultsfile has been successfully written to the './Final_Work/ep40_wm6000_b128_enh_clean_more_bl_tx_2h_2l_twit_emb_d06_dff256/' directory.\n",
            "Post Results Note: resutls are bad for wu 6000, maybe go in the opposite diretion?val_accuracy: 0.7242\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxKpqCbzSW6z"
      },
      "source": [
        "#End of File"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}